from IPython.display import Image
Image(url= "https://static1.squarespace.com/static/5006453fe4b09ef2252ba068/5095eabce4b06cb305058603/5095eabce4b02d37bef4c24c/1352002236895/100_anniversary_titanic_sinking_by_esai8mellows-d4xbme8.jpg")
import pandas as pd
import pandas_profiling # library for automatic EDA
%pip install autoviz # installing and importing autoviz, another library for automatic data visualization
from autoviz.AutoViz_Class import AutoViz_Class
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
import numpy as np
# data visualization
import seaborn as sns

from sklearn.linear_model import Perceptron
from sklearn.linear_model import SGDClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC, LinearSVC
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LogisticRegression
from sklearn import linear_model
train = pd.read_csv("../input/titanic/train.csv")
test = pd.read_csv("../input/titanic/test.csv")
print("Shape train data :",train.shape)
print("Shape test data :",test.shape)
def concat_df(train_data,test_data):
    return pd.concat([train_data,test_data],sort=True).reset_index(drop=True)
df_all = concat_df(train,test)
df_all.head()
df_all.shape
list(df_all.columns)
list(train.columns)
list(test.columns)
# The pandas profiling library is really useful on helping us understand the data we're working on.
# It saves us some precious time on the EDA process.
report = pandas_profiling.ProfileReport(train)
# Let's now visualize the report generated by pandas_profiling.
display(report)
# Also, there is an option to generate an .HTML file containing all the information generated by the report.
# report.to_file(output_file='report.html')
# Another great library for automatic EDA is AutoViz.
# With this library, several plots are generated with only 1 line of code.
# When combined with pandas_profiling, we obtain lots of information in a
# matter of seconds, using less then 5 lines of code.
AV = AutoViz_Class()

# Let's now visualize the plots generated by AutoViz.
report_2 = AV.AutoViz("../input/titanic/train.csv")
print("Missings in the train data : ")
display(train.isnull().sum())
print("=============================")
print("Missings in the test data : ")
display(test.isnull().sum())
train.Cabin.unique()
def process_age(df,cut_points,label_names):
    df["Age"] = df["Age"].fillna(-0.5)
    df["Age_categories"] = pd.cut(df["Age"],cut_points,labels=label_names)
    return df

cut_points = [-1,0,18,100]
label_names = ["Missing","Child","Adult"]

train = process_age(train,cut_points,label_names)
test = process_age(test,cut_points,label_names)
def process_age(df,cut_points,label_names):
    df["Age"] = df["Age"].fillna(-0.5)
    df["Age_categories"] = pd.cut(df["Age"],cut_points,labels=label_names)
    return df

cut_points = [-1,0, 5, 12, 18, 35, 60, 100]
label_names = ["Missing", 'Infant', "Child", 'Teenager', "Young Adult", 'Adult', 'Senior']

train = process_age(train,cut_points,label_names)
test = process_age(test,cut_points,label_names)

age_cat_pivot = train.pivot_table(index="Age_categories",values="Survived")
age_cat_pivot.plot.bar()
plt.show()
list(train.columns)
train.Pclass.unique()
train.Pclass.value_counts()
train.Pclass.value_counts().plot(kind='bar',color='red')
train.Sex.value_counts()
train.Sex.value_counts().plot(kind='bar',color='green')
column_name = "Pclass"
df = train
dummies = pd.get_dummies(df[column_name],prefix=column_name,drop_first=True)
dummies.head()
def create_dummies(df,column_name):
    dummies = pd.get_dummies(df[column_name],prefix=column_name)
    df = pd.concat([df,dummies],axis=1)
    return df

train = create_dummies(train,"Pclass")
test = create_dummies(test,"Pclass")
train.head()
train = create_dummies(train,"Sex")
test = create_dummies(test,"Sex")
train = create_dummies(train,"Age_categories")
test = create_dummies(test,"Age_categories")
train_copy = train.copy()
test_copy = test.copy()
train = train.drop(['Sex','Age','Age_categories'], axis=1)
test = test.drop(['Sex','Age','Age_categories'], axis=1)
train.head()

#from sklearn.linear_model import LogisticRegression
#lr = LogisticRegression()

list(train.columns)
columns1 = ['Pclass_1', 'Pclass_2', 'Pclass_3', 'Sex_female', 'Sex_male',
       'Age_categories_Missing','Age_categories_Infant',
       'Age_categories_Child', 'Age_categories_Teenager',
       'Age_categories_Young Adult', 'Age_categories_Adult',
       'Age_categories_Senior']
#lr.fit(train[columns], train['Survived'])

train['Survived']
#from sklearn.model_selection import train_test_split

#all_X = train[columns]
#all_y = train['Survived']

#train_X, test_X, train_y, test_y = train_test_split(
#    all_X, all_y, test_size=0.2,random_state=0)
#holdout = test # from now on we will refer to this
               # dataframe as the holdout data
#train_X.shape

#lr = LogisticRegression()
#lr.fit(train_X, train_y)
#predictions = lr.predict(test_X)
#lr = LogisticRegression()
#lr.fit(train_X, train_y)
#predictions = lr.predict(test_X)
#accuracy = accuracy_score(test_y, predictions)
#accuracy
#from sklearn.metrics import confusion_matrix

#conf_matrix = confusion_matrix(test_y, predictions)
#pd.DataFrame(conf_matrix, columns=['Survived', 'Died'], index=[['Survived', 'Died']])
#holdout.head()

#Making Predictions on Unseen Data
#lr = LogisticRegression()
#lr.fit(all_X, all_y)
#holdout_predictions = lr.predict(holdout[columns])
#holdout_predictions
#holdout_ids = holdout["PassengerId"]
#submission_df = {"PassengerId": holdout_ids,
#                 "Survived": holdout_predictions}
#submission = pd.DataFrame(submission_df)
#holdout_ids = holdout["PassengerId"]
#submission_df = {"PassengerId": holdout_ids,
#                 "Survived": holdout_predictions}
#submission = pd.DataFrame(submission_df)

#submission.to_csv('titanic_submission.csv', index=False)
from sklearn.ensemble import RandomForestClassifier
#rf = RandomForestClassifier()
#rf.fit(train_X, train_y)
#predictions = rf.predict(test_X)
#predictions_rf = rf.predict(test_X)
#accuracy_rf = accuracy_score(test_y, predictions_rf)
#accuracy_rf
train.isnull().sum()
test.isnull().sum()
test.loc[test['Fare'].isnull()]
mr_thomas = test.loc[(test['Pclass']==3) & (test['SibSp']==0) & (test['Embarked'] =='S')]['Fare'].median()
test.loc[test['Fare'].isnull(),'Fare'] = mr_thomas
test.isnull().sum()
target = train['Survived']
train.head()

test.head()
columns2 = ['Pclass_1', 'Pclass_2', 'Pclass_3', 'Sex_female', 'Sex_male',
       'Age_categories_Missing','Age_categories_Infant',
       'Age_categories_Child', 'Age_categories_Teenager',
       'Age_categories_Young Adult', 'Age_categories_Adult',
       'Age_categories_Senior','Embarked_C','Embarked_Q','Embarked_S','Fare']
columns3 = ['Pclass_1', 'Pclass_2', 'Pclass_3', 'Sex_female', 'Sex_male',
       'Age_categories_Missing','Age_categories_Infant',
       'Age_categories_Child', 'Age_categories_Teenager',
       'Age_categories_Young Adult', 'Age_categories_Adult',
       'Age_categories_Senior','Fare']
from sklearn.model_selection import train_test_split

all_X = train[columns1]
all_y = train['Survived']

train_X, test_X, train_y, test_y = train_test_split(
    all_X, all_y, test_size=0.2,random_state=0)
train_X.shape
train_y.shape
test_y.shape
test_X.shape
from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier()
rf.fit(train_X, train_y)
predictions = rf.predict(test_X)
predictions_rf2 = rf.predict(test_X)
accuracy_rf2 = accuracy_score(test_y, predictions_rf2)
accuracy_rf2
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score

accuracy = accuracy_score(test_y, predictions_rf2)
accuracy
conf_matrix = confusion_matrix(test_y, predictions_rf2)
pd.DataFrame(conf_matrix, columns=['Survived', 'Died'], index=[['Survived', 'Died']])
train.isnull().sum()
train.loc[train['Embarked'].isnull()]
#check for passengers wo were in passenger class 1, on deck abc and paid 80 or less for the tickets
train.loc[(train['Pclass']==1) & (train['Fare']<=80)]['Embarked'].value_counts()   
train.loc[train['Embarked'].isnull(),'Embarked'] ='S'
from sklearn.preprocessing import OneHotEncoder 
train.Embarked.unique()
a = pd.get_dummies(train.Embarked, prefix='Embarked')

a.head()
b = pd.get_dummies(test.Embarked, prefix='Embarked')

target = train['Survived']
train.Embarked.shape
test.Embarked.shape
frames = [train, a]
frames_1 = [test, b]

train = pd.concat(frames,axis=1)
test = pd.concat(frames_1,axis=1)
holdout = test # from now on we will refer to this
               # dataframe as the holdout data
train.Embarked_C.shape
train.shape
test.shape
test.Embarked.shape
from sklearn.model_selection import train_test_split

all_X = train[columns2]
all_y = target

train_X, test_X, train_y, test_y = train_test_split(
    all_X, all_y, test_size=0.2,random_state=0)

from xgboost import XGBClassifier

# fit model no training data
model = XGBClassifier()
model.fit(train_X, train_y)
predictions_xgb = model.predict(test_X)
accuracy_xgb = accuracy_score(test_y, predictions_xgb)
accuracy_xgb
conf_matrix3 = confusion_matrix(test_y, predictions_xgb)
pd.DataFrame(conf_matrix, columns=['Survived', 'Died'], index=[['Survived', 'Died']])
holdout_predictions = model.predict(holdout[columns2])
holdout_predictions
holdout_ids = holdout["PassengerId"]
submission_df = {"PassengerId": holdout_ids,
                 "Survived": holdout_predictions}
submission = pd.DataFrame(submission_df)

submission.to_csv('titanic_submission2.csv', index=False)
data = [train, test]
for dataset in data:
    dataset['relatives'] = dataset['SibSp'] + dataset['Parch']
    dataset.loc[dataset['relatives'] > 0, 'not_alone'] = 0
    dataset.loc[dataset['relatives'] == 0, 'not_alone'] = 1
    dataset['not_alone'] = dataset['not_alone'].astype(int)
train['not_alone'].value_counts()
axes = sns.factorplot('relatives','Survived', 
                      data=train, aspect = 2.5, )
X_train = train[columns2]
Y_train = train["Survived"]
X_test  = test.drop("PassengerId", axis=1).copy()
sgd = linear_model.SGDClassifier(max_iter=5, tol=None)
sgd.fit(X_train, Y_train)
Y_pred = sgd.predict(test_X)

sgd.score(train_X, train_y)

acc_sgd = round(sgd.score(train_X, train_y) * 100, 2)
random_forest = RandomForestClassifier(n_estimators=100)
random_forest.fit(train_X, train_y)

Y_prediction_rf = random_forest.predict(test_X)

random_forest.score(train_X, train_y)
acc_random_forest = round(random_forest.score(train_X, train_y) * 100, 2)

knn = KNeighborsClassifier(n_neighbors = 3)
knn.fit(train_X, train_y)
Y_pred = knn.predict(test_X)
acc_knn = round(knn.score(train_X, train_y) * 100, 2)
logreg = LogisticRegression()
logreg.fit(train_X, train_y)

Y_pred = logreg.predict(test_X)

acc_log = round(logreg.score(train_X, train_y) * 100, 2)
gaussian = GaussianNB()
gaussian.fit(train_X, train_y)
Y_pred = gaussian.predict(test_X)
acc_gaussian = round(gaussian.score(train_X, train_y) * 100, 2)
perceptron = Perceptron(max_iter=5)
perceptron.fit(train_X, train_y)

Y_pred = perceptron.predict(test_X)

acc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)
linear_svc = LinearSVC()
linear_svc.fit(train_X, train_y)

Y_pred = linear_svc.predict(test_X)

acc_linear_svc = round(linear_svc.score(train_X, train_y) * 100, 2)
decision_tree = DecisionTreeClassifier()
decision_tree.fit(train_X, train_y)
Y_pred = decision_tree.predict(test_X)
acc_decision_tree = round(decision_tree.score(train_X, train_y) * 100, 2)
results = pd.DataFrame({
    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', 
              'Random Forest', 'Naive Bayes', 'Perceptron', 
              'Stochastic Gradient Decent', 
              'Decision Tree'],
    'Score': [acc_linear_svc, acc_knn, acc_log, 
              acc_random_forest, acc_gaussian, acc_perceptron, 
              acc_sgd, acc_decision_tree]})
result_df = results.sort_values(by='Score', ascending=False)
result_df = result_df.set_index('Score')
result_df.head(9)
from sklearn.model_selection import cross_val_score
rf = RandomForestClassifier(n_estimators=100)
scores = cross_val_score(rf, train_X, train_y, cv=10, scoring = "accuracy")
print("Scores:", scores)
print("Mean:", scores.mean())
print("Standard Deviation:", scores.std())
importances = pd.DataFrame({'feature':train_X.columns,'importance':np.round(random_forest.feature_importances_,3)})
importances = importances.sort_values('importance',ascending=False).set_index('feature')
importances.head(15)
importances.plot.bar()
"""holdout_predictions = random_forest.predict(holdout[columns2])
holdout_predictions"""
""" holdout_ids = holdout["PassengerId"]
submission_df = {"PassengerId": holdout_ids,
                 "Survived": holdout_predictions}
submission = pd.DataFrame(submission_df)

submission.to_csv('titanic_submission_3.csv', index=False)"""