from IPython.display import Image

Image("../input/jobbulletindata/results.png")
from IPython.display import Image

Image("../input/jobbulletindata/nonnative-2.png")
from IPython.display import Image

Image("../input/jobbulletindata/nonnative.png")
from IPython.display import Image

Image("../input/jobbulletindata/male.png")

from IPython.display import Image

Image("../input/jobbulletindata/male2.png")
from IPython.display import Image

Image("../input/jobbulletindata/female.png")
from IPython.display import Image

Image("../input/jobbulletindata/female2.png")
'''

Script:     biasFinder.py

Project:    City of Los Angeles Job Bulletin analysis

Purpose:    Extract data from bias terms analysis into a csv file:



CSV database row types:



JobClass   TermLocation   Term            Bias

1117       None           None            gender_terms       #example when no biased terms are found by the detector

1117       [1554-1565]    examination     native_speakers    #when possibly biased terms are found, record term location offsets, term, and detector

'''



import os

import pandas as pd

import re

import string



def process_file(jobClass, file, b, skip_language_recommendations):

    '''

    Parse bias detector files generated by gender-bias toolkit



    jobClass - 4 digit number

    file - file generated by gender-bias toolkit

    b - list for storing results

    skip_language_recommendations - gender-bias toolkit stores recommendations for synonyms in these files but this information is not used here so skip it

    

    '''

    r = []  # list for each row of terms

    bias = ''

    strippables = "!#$%&'()*+,-./;<=>?@\^_`{|}~" + string.whitespace



    f = open(file)

    for line in f:

        line = line.strip(strippables)

        if skip_language_recommendations:

            if line.startswith('Consider replacing'):

                continue

        if line.startswith('Unnecessary use of gender terms'):

                bias = 'gender_terms'

        elif line.startswith('Terms biased towards native speakers'):

                bias = 'native_speakers'

        elif line.startswith('Terms focusing on effort vs accomplishment'):

                bias = 'effort_accomplishment'            

        elif line.startswith('Terms about personal life'):

                bias = 'personal_life'

        elif line.startswith('Terms biased towards men'):

                bias = 'male_terms'

        elif line.startswith('Terms biased towards women'):

                bias = 'female_terms'



        elif 'SUMMARY: Too few words about concrete accomplishments' in line:

            r.append(jobClass)

            r.append('0-0')

            r.append('none')

            r.append(bias)

            b.append(r)

            r = []



        elif 'SUMMARY: None' in line:

            r.append(jobClass)

            r.append('0-0')

            r.append('none')

            r.append(bias)

            b.append(r)

            r = []



        elif line.startswith('['):

            terms = line.split(':')

            termLocation = terms[0].strip('[]')

            term = terms[1].strip(' ')

            if "=" in term:

                continue

            elif "/" in term:

                continue

            else:

                r.append(jobClass)

                r.append(termLocation)

                r.append(term)

                r.append(bias)

                b.append(r)

            r = []

    return b



def main():

    LAJobFiles = [os.path.join(root, file) for root, folder, LAJobFile in os.walk('../input/jobbulletindata/JBR_BiasText/') for file in LAJobFile]

    print("\n",len(LAJobFiles), "LA Job Files\n")



    b = []    

    biasAnalysis = [process_file(LAJobFile[:4], LAJobFile, b, skip_language_recommendations=True) for LAJobFile in LAJobFiles]

    ba = pd.DataFrame(biasAnalysis[0], columns=('JobClass','TermLocation','Term','Bias'))



    #print("\nSample rows")

    #print(ba.head(5))

    # TODO - consider replacing job classes with ###. with 0###

    ba.to_csv('biasTerms.csv', index=False)



    baTerms = ba['Term'].unique()

    print("\n")

    print((len(baTerms)-1), " possible biased words\n")

    #print(baTerms[1:])



if __name__ == '__main__':

    main()

'''

Script:     biasTermsAnalyzer.py

Purpose:    Evaluated possible bias terms found in City of Los Angeles Job Bulletins

'''



import pandas as pd

import numpy as np

import matplotlib.pyplot as plt

import re

from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator



pd.options.display.max_columns=5



def main():

    '''

    input files:



        ba             bias analysis DataFrame input from: /JBR_Output/biasTerms.csv

        simpleWords    list of English synonyms for complex terms input from /genderbias/nativespeakers/Englishwords.wordlist

        nonBiasTerms   terms specific to City of Los Angeles input from /JBR_Resources/nonBiasTerms.csv



    output files:



        fo             output file with recommendations        JBR_Output/BiasStudyRecommendations.txt       

    '''

    

    fo = open("BiasStudyRecommendations.txt", "w+")

    ba = pd.read_csv('../input/jobbulletindata/JBR_Output/biasTerms.csv', dtype='str')



    print("STATISTICS:\n", file=fo)

    print("STATISTICS:\n")



    # Number of job classes processed

    jobClasses = ba['JobClass'].unique()

    possiblyUsed = len(ba)

    a = len(jobClasses)

    print(a, " job classes evaluated\n", file=fo)

    print("Biased terms may have been used ", possiblyUsed," times\n", file=fo)

    print(a, " job classes evaluated\n")

    print("Biased terms may have been used ",possiblyUsed," times\n")



    # Bias categories (also called bias detectors)

    biasCats = ba['Bias'].unique().tolist()

    print(len(biasCats), ' bias detectors used:', file=fo)

    print(len(biasCats), ' bias detectors used:')

    print(biasCats, "\n", file=fo)

    print(biasCats, "\n")

 

    # Possible biased words found

    biasTerms = ba['Term'].unique().tolist()

    biasTerms.sort()

    possiblyBiased = len(biasTerms) - 1

    print(possiblyBiased, " unique words were found :\n ", biasTerms[1:], file=fo)

    print(possiblyBiased, " unique words were found:\n ", biasTerms[1:])





    # NATIVE LANGUAGE BIASES

    complexTermsCnt = pd.value_counts(ba['Term'].loc[ba['Bias']=='native_speakers'], ascending=True)



    # WordCloud

    wordcloud = WordCloud(max_font_size=30, max_words=20,background_color="white").generate(complexTermsCnt.sort_values(ascending=False).head(20).to_string())

    plt.imshow(wordcloud, interpolation='bilinear')

    plt.axis('off')

    plt.title('Words that can be simplifed for non-native speakers')

    plt.show()



    # Horizontal bar graph

    complexTermsCnt = complexTermsCnt.tail(20)

    complexTermsCnt.plot(figsize=(10,5), x='Count', y='Complex Term', kind='barh', color='black', title='Words that can be simplified for non-native speakers')

    plt.show()



    print("\nNATIVE LANGUAGE BIASES", file=fo)



    # Words that can be simplified for non-native speakers

    print("\nWords that can be simplifed for non-native speakers:", file=fo)

    print("\nWord       Number of times used", file=fo)

    print("\nWords that can be simplifed for non-native speakers:")

    print("\nWord       Number of times used")

    print("\n", complexTermsCnt.sort_values(ascending=False), file=fo)

    print("\n", complexTermsCnt.sort_values(ascending=False))



    # Recommend shorter synonyms

    print("\nRECOMMENDATIONS: use simple language:\n", file=fo)

    print("\nRECOMMENDATIONS: use simple language:\n")

    # lookup synonyms

    simpleWords = pd.read_csv('../input/jobbulletindata/Englishwords.wordlist')

    c = ba['Term'].loc[ba['Bias']=='native_speakers'].unique()

    complexWords = pd.DataFrame(data=c.flatten(), columns = ['Used'])

    # find the shortest two synonyms for complex words

    synonyms = pd.merge(complexWords, simpleWords, how='left')

    synonyms.dropna(subset=['Recommend1'], inplace=True)

    print(synonyms, file=fo)

    print(synonyms)

    print("\nBiasStudyResults.txt contains instructions for finding sentences where biased words are used.")



    # GENDER-BIASED TERMS

    maleTerms = pd.value_counts(ba['Term'].loc[ba['Bias']=='male_terms'], ascending=True)

    maleTerms = maleTerms.tail(20)



    # WordCloud

    wordcloud = WordCloud(max_font_size=50, max_words=100,background_color="white", colormap="Blues").generate(maleTerms.to_string())

    plt.imshow(wordcloud, interpolation='bilinear')

    plt.axis('off')

    plt.title("Top 20 Possible Male-biased Terms")

    plt.show()



    # Horizontal bar graph

    maleTerms.plot(figsize=(10,6), x='Count', y='Male Biased', kind='barh', title='Top 20 possible male biased terms')

    plt.show()

    print("\nGENDER BIASES", file=fo)

    print('\nPossible male-biased terms:', file=fo)

    print("\nWord       Number of times used", file=fo)



    print("\nGENDER BIASES")

    print('\nPossible male-biased terms:')

    print("\nWord       Number of times used")

    print(maleTerms.sort_values(ascending=False), file=fo)

    print(maleTerms.sort_values(ascending=False))

        

    femaleTerms = pd.value_counts(ba['Term'].loc[ba['Bias'].isin(['female_terms','personal_life','gender_terms','effort_accommplishment'])], ascending=True)

    femaleTerms = femaleTerms.tail(20)



    # WordCloud

    wordcloud = WordCloud(max_font_size=50, max_words=100,background_color="white", colormap="PuRd").generate(femaleTerms.to_string())

    plt.imshow(wordcloud, interpolation='bilinear')

    plt.title("Top 20 Possible Female-biased Terms")

    plt.axis('off')

    plt.show()



    # Horizontal bar graph

    femaleTerms[:-1].plot(figsize=(10,6), x='Count', y='Female Biased', kind='barh', color='red', title='Top 20 possible female biased terms')

    plt.show()

    print('\nPossible female-biased terms:', file=fo)

    print("\nWord       Number of times used", file=fo)

    print('\nPossible female-biased terms:')

    print("\nWord       Number of times used")

    print(femaleTerms[:-1].sort_values(ascending=False), file=fo)

    print(femaleTerms[:-1].sort_values(ascending=False))



    fo.close()

    

if __name__ == '__main__':

    main()

'''

Script:  biasVerifier

Purpose: create log and csv file with biased words



Files:



BiasStudyResults.txt

biasTerms.csv

'''

import os

import pandas as pd

import re

import numpy as np

import matplotlib.pyplot as plt

from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator





def getJobClass(JobBulletins):

    '''

        get the Job Class number from the filename where filename is JobBulletin and Job Class is always the first 4 digits after the name and before the version and date

    '''

    jbDict = {}

    for JobBulletin in JobBulletins:

        #JobBulletin = re.sub("[/]","/'",JobBulletin)   # original folder structure.  use JobClass[1:5]

        JobBulletin = re.sub("../input/jobbulletindata/JBR_Output/", "", JobBulletin)  # kaggle folder structure us JobClass[2:6]

        JobBulletin = re.sub("txt", "txt'",JobBulletin)

        JobClass = re.sub('[a-zA-Z /]','',JobBulletin)

        jbDict[JobClass[2:6]] = JobBulletin

    return jbDict



def getWordLocation(loc):

        ''' get the beginning and ending offsets'''

        return loc.split('-')



def getNLPstats():

    # get the stats from JBR_NLP.py

    with open ("../input/jobbulletindata/JBR_Output/totWords.txt") as fs:

        return [line.strip("\n") for line in fs]



def printLog(fo,msg, fileOnly=False):

    if fileOnly:

        print(msg,file=fo)

    else:

        print(msg, file=fo)

        print(msg)



def main():



    fo = open("BiasStudyResults.txt", "w+")

    ba = pd.read_csv('../input/jobbulletindata/JBR_Output/biasTerms.csv', dtype='str')  



    # find the number of job classes processed

    jobClasses = ba['JobClass'].unique()

    possiblyUsed = len(ba)



    # get the Job Bulletins from the JobBulletin folder

    JobBulletins = [os.path.join(root, file) for root, folder, JobBulletin in os.walk('../input/jobbulletindata/JobBulletins') for file in JobBulletin]



    # get jobclass from filename

    jbDict = getJobClass(JobBulletins)

    #jb = pd.DataFrame.from_dict(jbDict.items())   # code works in Ubuntu

    #jb.columns=('JobClass', 'jbFilename')         # code works in Ubuntu

    jb = pd.DataFrame(list(jbDict.items()),columns=['JobClass','jbFilename'])    # code works on Kaggle



    printLog(fo,"VERIFYING WHETHER WORDS ARE BIASED: ")

    printLog(fo,"\nFirst, I read " + str(len(JobBulletins)) + " Job Bulletins and found words that may be biased") 



    # get a list of words that we know are not biased

    notBias = pd.read_csv('../input/jobbulletindata/JBR_Resources/nonBiasTerms.csv')

    printLog(fo,"Then, I checked these words against the not-biased list which contains " + str(len(notBias))+ " words")

    

    # get the list of possibly biased terms from gender-bias output

    b = ba['Term'].loc[ba['Bias'].isin(['female_terms','personal_life','gender_terms','effort_accommplishment', 'male_terms'])].unique()

    b = b[1:]     # remove 'none'

    possibleBias = pd.DataFrame(data=b.flatten(), columns=['Term'])



    # "subtract" the not-biased words so we have a list of words to be verified

    bias = pd.merge(possibleBias,notBias,how='left')

    printLog(fo,"After checking the not-biased list, there are " + str(len(bias)) + " words that need to be verified.  ")



    # find the location of each biased word in each Job Bulletin

    verifyWords = pd.merge(bias,ba,how='inner')

    printLog(fo,"Biased words may have been used " + str(len(verifyWords)) + " times, but more analysis is needed.")



    # find the Job Bulletins where biased words are located

    vWordsFilename = pd.merge(verifyWords, jb, how='inner')

    printLog(fo,"\nHere's a partial list:")

    pd.options.display.max_columns=5

    printLog(fo,vWordsFilename.head(10))

    

    biasedTerms = []                # for reporting a summary of biased terms

    biasedRow = []                  # for recording each row of biased terms

    kF = 0                          # count the number of files opened

    kFP = 0                         # count the number of false positives



    # look up each biased word and print out the phrase where it is used

    # open each Job Bulletin file only once and process all the biased words in that file then close it

    priorFilename = ''

    for i, row in vWordsFilename.iterrows():

        filename = re.sub('[\']','',row["jbFilename"])  # strip the single quote so the file will open

        biasedRow.append(filename)  # store the filename WITHOUT quote so it matches the filename from JBR_NLP.py.  Thus the final statistics will be computed properly

        

        # open the Job Bulletin once but verify many words

        if priorFilename != filename:

            try:

                f.close()

                priorFilename = filename

            except:

                if len(priorFilename) > 0:

                    print(priorFilename, " STILL OPEN")

            try:

                f = open(filename)

                kF +=1

            except:

                print("DOUBLE CHECK THIS FILE: ", filename)

                continue



        # get the phrase where the biased word is located

        loc = getWordLocation(row['TermLocation'])

        msg = "VERIFIED that '" + row['Term'] + "' can be found at offset: " + str(int(loc[0])) + " for Job Class: " + row['JobClass'] + " in Job Bulletin: " + row['jbFilename']



        z = 100             # read z characters after the biased word

        sentence = ''       # capture the phrase with biased word

        offset = 0          # beginning offset



        _text = f.read()

        offset = _text.find(row['Term'], offset)

        f.seek(int(loc[0]))

        for k in range(offset, offset+z):

            ch = f.read(1)

            if k == offset:

                sentence += " >>> "

            if k == offset + len(row['Term']):

                sentence += " <<< "

            sentence += ch

        row["SENTENCE"] = sentence



        # store the results

        biasedRow.append(row["JobClass"])

        biasedRow.append(row["TermLocation"])

        biasedRow.append(row["Term"])

        biasedRow.append(row["Bias"])

        biasedRow.append(row["SENTENCE"])

        biasedTerms.append(biasedRow)

        biasedRow = []

        

        printLog(fo,"\n\nPHRASE FROM JOB BULLETIN MAY HAVE MULTIPLE LINES:\n" + sentence + "...", fileOnly=True)

        printLog(fo,msg, fileOnly=True)



        # report false positives

        searchTerm = row['Term'].lower()

        falsePositive = re.search(searchTerm, sentence.lower())

        if not falsePositive:

            printLog(fo,"FALSE REPORT WARNING:  the term found doesn't match the search term", fileOnly=True)

            kFP += 1



    # REPORT TERMS LIKELY TO BE BIASED

    likelyBiased = len(biasedTerms)

    biasedDF = pd.DataFrame(biasedTerms, columns=('FILE_NAME', 'JOB_CLASS', 'WORD_LOCATION','WORD','BIAS','SENTENCE'))

    biasedDF.index.name = 'IDX'

    results = biasedDF['WORD'].unique()

    

    score = ((likelyBiased - kFP) / possiblyUsed * 100)

    totals = getNLPstats()

    percentBiased = (len(results) / int(totals[1])) * 100



    # print results

    printLog(fo,"\nWhen I began, I thought that biased words were used  " + str(possiblyUsed) + "  times.  ")

    printLog(fo,"After verifying, I believe that biased words are used  " + str(likelyBiased - kFP) + "  times")

    printLog(fo,"I verified each word by looking up the phrase where the word was used.  If the word was not found, then I reported a false positive")

    printLog(fo, str(kFP) + "  false positives were found")

    printLog(fo,"\n" + str(np.round(score,0)) + "% percent of the time biased words are used in Job Bulletins (A lower score is better.  0% is a perfect score)\n")

    printLog(fo, str(np.round(percentBiased,0)) + "% of the words are biased")

    printLog(fo,"\n" + str(len(results)) + " words that may be biased:\n" + str(results))



    # WordCloud

    wordcloud = WordCloud(max_font_size=50, max_words=100,background_color="white").generate(biasedDF['WORD'].to_string())

    plt.imshow(wordcloud, interpolation='bilinear')

    plt.axis('off')

    plt.title('Words used in Job Bulletins that discourage applicants')

    plt.show()



    # save results in a csv file

    biasedDF.to_csv("BiasedWords.csv")



if __name__ == '__main__':

    main()