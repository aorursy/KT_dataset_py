# This Python 3 environment comes with many helpful analytics libraries installed

# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python

# For example, here's several helpful packages to load



import numpy as np # linear algebra

import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)



# Input data files are available in the read-only "../input/" directory

# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory



import os

for dirname, _, filenames in os.walk('/kaggle/input'):

    for filename in filenames:

        print(os.path.join(dirname, filename))



# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 

# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session
df_pgen1 = pd.read_csv('../input/solar-power-generation-data/Plant_1_Generation_Data.csv');

df_pgen2 = pd.read_csv('../input/solar-power-generation-data/Plant_2_Generation_Data.csv');

df_wsen1 = pd.read_csv('../input/solar-power-generation-data/Plant_1_Weather_Sensor_Data.csv');

df_wsen2 = pd.read_csv('../input/solar-power-generation-data/Plant_2_Weather_Sensor_Data.csv');

#loading the csv files into the dataframes

#exploring the data sets

df_pgen1.head()
df_wsen1.head()
df_pgen2.info()
df_wsen2.describe()
#pre-processing, converting the date time from object data type (string) to datetime type

df_pgen1['DATE_TIME'] = pd.to_datetime(df_pgen1['DATE_TIME'],format = '%d-%m-%Y %H:%M')

df_pgen2["DATE_TIME"] = pd.to_datetime(df_pgen2["DATE_TIME"],format = "%Y-%m-%d %H:%M:%S")



#creating seperate fields for DATE and TIME (still in object type)

df_pgen1["DATE"] = df_pgen1["DATE_TIME"].apply(lambda x:x.date())

df_pgen1["TIME"] = df_pgen1["DATE_TIME"].apply(lambda x:x.time())

df_pgen2["DATE"] = df_pgen2["DATE_TIME"].apply(lambda x:x.date())

df_pgen2["TIME"] = df_pgen2["DATE_TIME"].apply(lambda x:x.time())



#converting the TIME field into hours and minutes (integer) and date field to datetime type

df_pgen1["HOUR"] = pd.to_datetime(df_pgen1["TIME"],format= "%H:%M:%S").dt.hour;

df_pgen1["MINUTE"] = pd.to_datetime(df_pgen1["TIME"],format = "%H:%M:%S").dt.minute;

df_pgen1['DATE'] = pd.to_datetime(df_pgen1['DATE'],format = '%Y-%m-%d');

df_pgen2["HOUR"] = pd.to_datetime(df_pgen2["TIME"],format="%H:%M:%S").dt.hour;

df_pgen2["HOUR"] = pd.to_datetime(df_pgen2["TIME"],format="%H:%M:%S").dt.hour;

df_pgen2['DATE'] = pd.to_datetime(df_pgen2['DATE'],format = '%Y-%m-%d')







#Mean daily yield of both plants

print(df_pgen1["DAILY_YIELD"].mean());

df_pgen2["DAILY_YIELD"].mean()
#Total irradiation per day = total irradiation/number of days

#this is the average total irradiation falling on all the weather sensors of the plant per day. There are 34 days.

net_irrad = 0;

for index, row in df_wsen1.iterrows():

    net_irrad = net_irrad + row["IRRADIATION"]

print("total irradiation is",(net_irrad/34))
#Maximum module temperature of both sensors



print("Maximum module temperature at any time on any day across dataset of sensor 1=",df_wsen1["MODULE_TEMPERATURE"].max());

print("Maximum module temperature at any time on any day across dataset of sensor 2=",df_wsen2["MODULE_TEMPERATURE"].max());
#Maximum ambient temperature of both sensors



print("Maximum ambient temperature at any time on any day across dataset of sensor 1=",df_wsen1["AMBIENT_TEMPERATURE"].max());

print("Maximum ambient temperature at any time on any day across dataset of sensor 2=",df_wsen2["AMBIENT_TEMPERATURE"].max());
#How many inverters are there for each plant



print("Number of unique invertors in plant 1=",len(df_pgen1["SOURCE_KEY"].unique()));

print("Number of unique invertors in plant 2=",len(df_pgen2["SOURCE_KEY"].unique()));     
#maximum and minimum dc and ac power generated in any time interval:



print("Max DC in any time interval at plant 1=",df_pgen1["DC_POWER"].max(),"which was generated by the inverter:",df_pgen1["SOURCE_KEY"].loc[df_pgen1["DC_POWER"].idxmax()])

print("Max DC in any time interval at plant 2=",df_pgen2["DC_POWER"].max(),"which was generated by the inverter:",df_pgen2["SOURCE_KEY"].loc[df_pgen2["DC_POWER"].idxmax()])

print("")

print("Minimum DC in any time interval at plant 1=",df_pgen1["DC_POWER"].min(),"which was generated by the inverter:",df_pgen1["SOURCE_KEY"].loc[df_pgen1["DC_POWER"].idxmin()])

print("Minimum DC in any time interval at plant 2=",df_pgen2["DC_POWER"].min(),"which was generated by the inverter:",df_pgen2["SOURCE_KEY"].loc[df_pgen2["DC_POWER"].idxmin()])



print("")



print("Max AC in any time interval at plant 1=",df_pgen1["AC_POWER"].max(),"which was generated by the inverter:",df_pgen1["SOURCE_KEY"].loc[df_pgen1["AC_POWER"].idxmax()])

print("Max AC in any time interval at plant 2=",df_pgen2["AC_POWER"].max(),"which was generated by the inverter:",df_pgen2["SOURCE_KEY"].loc[df_pgen2["AC_POWER"].idxmax()])

print("")

print("Minimum AC in any time interval at plant 1=",df_pgen1["AC_POWER"].min(),"which was generated by the inverter:",df_pgen1["SOURCE_KEY"].loc[df_pgen1["AC_POWER"].idxmin()])

print("Minimum AC in any time interval at plant 2=",df_pgen2["AC_POWER"].min(),"which was generated by the inverter:",df_pgen2["SOURCE_KEY"].loc[df_pgen2["AC_POWER"].idxmin()])
#Ranking the inverters based on DC and AC power generated

print(df_pgen1.sort_values(by='DC_POWER'))

print(df_pgen2.sort_values(by='DC_POWER'))



print(df_pgen1.sort_values(by='AC_POWER'))

print(df_pgen2.sort_values(by='AC_POWER'))



#Looking for missing data



df_pgen1['DATE'].value_counts()



#There are less than the expected number of data points recorded on multiple dates, as can be seen when they have less than 2112 rows for each date