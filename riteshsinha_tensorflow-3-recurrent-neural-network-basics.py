import numpy as np # linear algebra

import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

import tensorflow as tf

import matplotlib.pyplot as plt

%matplotlib inline

import os
class TimeSeriesData():

    def __init__(self, num_points, xmin, xmax):

        # TimeSeries Data being built with Sine function.

        self.xmin = xmin

        self.xmax = xmax

        self.num_points = num_points

        self.resolution = (xmax- xmin) / num_points

        self.x_data = np.linspace(xmin, xmax, num_points)

        self.y_true = np.sin(self.x_data)

    

    def return_truth (self, xseries):

        return np.sin(xseries)

    # The next_batch function is used to return data from the data generated by TimeSeriesData constructor.The ts_start

    # values are brought to the timeseries data range. This is used down the kernel.

    def next_batch(self, batch_size, steps, return_batch_ts = False):

        rand_start = np.random.rand(batch_size, 1)

        ts_start = rand_start * (self.xmax - self.xmin - (steps*self.resolution))

        batch_ts = ts_start + np.arange(0, steps + 1 ) * self.resolution

        y_batch = np.sin(batch_ts)

        if return_batch_ts:

            return(y_batch[:,:-1].reshape(-1, steps, 1), y_batch[:,1:].reshape(-1, steps, 1), batch_ts)

        else:

            return(y_batch[:,:-1].reshape(-1, steps, 1), y_batch[:,1:].reshape(-1, steps, 1))
ts_data = TimeSeriesData(250,0,10) # Creating 250 equally spaced points between 0 and 10

plt.plot(ts_data.x_data, ts_data.y_true) # Looking at the data generated above.
num_time_steps = 30 

train_inst =np.linspace(5, 5 + ts_data.resolution*(num_time_steps+1), num_time_steps + 1)

plt.title = "A Training Instance"

plt.plot(train_inst[:-1,], ts_data.return_truth(train_inst[:-1]), 'bo', markersize = 15, label = "training instance")

plt.plot(train_inst[1:], ts_data.return_truth(train_inst[1:]), 'ko', markersize = 5, label = "test instance")

plt.legend()
tf.reset_default_graph()

num_inputs = 1

num_outputs = 1

num_neurons = 100

learning_rate = 0.001

num_train_iterations = 200

batch_size = 1

X = tf.placeholder(tf.float32, [None, num_time_steps, num_inputs])

y = tf.placeholder(tf.float32, [None, num_time_steps, num_outputs]) 

seq_length = tf.placeholder(tf.int32, [None])

cell = tf.contrib.rnn.OutputProjectionWrapper(tf.contrib.rnn.BasicRNNCell(num_units = num_neurons, activation = tf.nn.relu), output_size = num_outputs)

outputs, states = tf.nn.dynamic_rnn( cell, X,  dtype=tf.float32)

# Mean Squared Error 

loss = tf.reduce_mean(tf.square(outputs - y))

optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)

train = optimizer.minimize(loss)
# Session 

init = tf.global_variables_initializer()

#saver = tf.train.Saver()

with tf.Session() as sess:

    sess.run(init)

    for iteration in range(num_train_iterations):

        X_batch, y_batch = ts_data.next_batch(batch_size, num_time_steps)

        sess.run(train, feed_dict = {X:X_batch, y:y_batch})

        if iteration % 100 == 0:

            mse = loss.eval(feed_dict = {X:X_batch, y:y_batch})

            print(iteration, "\tMSE:", mse)

#saver.save(sess, "./testrnn")

    # USING THE SAME SESSION WHICH WAS OPENED ABOVE.

    X_new = np.sin(np.array(train_inst[:-1].reshape(-1, num_time_steps, num_inputs)))

    y_pred = sess.run(outputs, feed_dict = {X:X_new})

    print("done")

# TESTING THE MODEL

#plt.title("Model Testing")

plt.plot(train_inst[:-1], np.sin(train_inst[:-1]), "bo", markersize = 15, alpha = 0.3, label = "training Instance")

# Prediction

plt.plot(train_inst[1:], np.sin(train_inst[1:]), "ko", markersize = 15, alpha = 0.3, label = "target")

# Model Prediction

plt.plot(train_inst[1:], y_pred[0,:,0],'r.', markersize =10, label = "PREDICTIONS")

plt.legend()

plt.tight_layout()
tf.reset_default_graph()

num_inputs = 1

num_outputs = 1

num_neurons = 100

learning_rate = 0.001

num_train_iterations = 1000

batch_size = 1

X = tf.placeholder(tf.float32, [None, num_time_steps, num_inputs])

y = tf.placeholder(tf.float32, [None, num_time_steps, num_outputs]) 

seq_length = tf.placeholder(tf.int32, [None])

cell = tf.contrib.rnn.OutputProjectionWrapper(tf.contrib.rnn.BasicRNNCell(num_units = num_neurons, activation = tf.nn.relu), output_size = num_outputs)

outputs, states = tf.nn.dynamic_rnn( cell, X,  dtype=tf.float32)

# Mean Squared Error 

loss = tf.reduce_mean(tf.square(outputs - y))

optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)

train = optimizer.minimize(loss)

# Mean Squared Error 

loss = tf.reduce_mean(tf.square(outputs - y))

optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)

train = optimizer.minimize(loss)

# Session 

init = tf.global_variables_initializer()

saver = tf.train.Saver()

with tf.Session() as sess:

    sess.run(init)

    for iteration in range(num_train_iterations):

        X_batch, y_batch = ts_data.next_batch(batch_size, num_time_steps)

        sess.run(train, feed_dict = {X:X_batch, y:y_batch})

        if iteration % 100 == 0:

            mse = loss.eval(feed_dict = {X:X_batch, y:y_batch})

            print(iteration, "\tMSE:", mse)

#saver.save(sess, "./testrnn")

    # USING THE SAME SESSION WHICH WAS OPENED ABOVE.

    X_new = np.sin(np.array(train_inst[:-1].reshape(-1, num_time_steps, num_inputs)))

    y_pred = sess.run(outputs, feed_dict = {X:X_new})

    print("Training done.")



    # TESTING THE MODEL

plt.plot(train_inst[:-1], np.sin(train_inst[:-1]), "bo", markersize = 15, alpha = 0.3, label = "training Instance")

# Prediction

plt.plot(train_inst[1:], np.sin(train_inst[1:]), "ko", markersize = 12, alpha = 0.3, label = "target")

plt.plot(train_inst[1:], y_pred[0,:,0],'r.', markersize =10, label = "PREDICTIONS")

plt.legend()

plt.tight_layout()
tf.reset_default_graph()

num_inputs = 1

num_outputs = 1

num_neurons = 100

learning_rate = 0.001

num_train_iterations = 1000

batch_size = 1

X = tf.placeholder(tf.float32, [None, num_time_steps, num_inputs])

y = tf.placeholder(tf.float32, [None, num_time_steps, num_outputs]) 

seq_length = tf.placeholder(tf.int32, [None])

cell = tf.contrib.rnn.OutputProjectionWrapper(tf.contrib.rnn.GRUCell(num_units = num_neurons, activation = tf.nn.relu), output_size = num_outputs)

outputs, states = tf.nn.dynamic_rnn( cell, X,  dtype=tf.float32)

# Mean Squared Error 

loss = tf.reduce_mean(tf.square(outputs - y))

optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)

train = optimizer.minimize(loss)

# Mean Squared Error 

loss = tf.reduce_mean(tf.square(outputs - y))

optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)

train = optimizer.minimize(loss)

# Session 

init = tf.global_variables_initializer()

#saver = tf.train.Saver()

with tf.Session() as sess:

    sess.run(init)

    for iteration in range(num_train_iterations):

        X_batch, y_batch = ts_data.next_batch(batch_size, num_time_steps)

        sess.run(train, feed_dict = {X:X_batch, y:y_batch})

        if iteration % 100 == 0:

            mse = loss.eval(feed_dict = {X:X_batch, y:y_batch})

            print(iteration, "\tMSE:", mse)

#saver.save(sess, "./testrnn")

    # USING THE SAME SESSION WHICH WAS OPENED ABOVE.

    X_new = np.sin(np.array(train_inst[:-1].reshape(-1, num_time_steps, num_inputs)))

    y_pred = sess.run(outputs, feed_dict = {X:X_new})

    print("Training done.")



# TESTING THE MODEL



plt.plot(train_inst[:-1], np.sin(train_inst[:-1]), "bo", markersize = 15, alpha = 0.3, label = "training Instance")

# Prediction

plt.plot(train_inst[1:], np.sin(train_inst[1:]), "ko", markersize = 12, alpha = 0.3, label = "target")

# Model Prediction

plt.plot(train_inst[1:], y_pred[0,:,0],'r.', markersize = 10, label = "PREDICTIONS")

plt.legend()

plt.tight_layout()

#mse_pred = (y_pred - np.sin(train_inst[1:])) ^2