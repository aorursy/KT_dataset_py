#Problem---Load a preexisting sample datasets
#Solution---We willuse scikit-learn library

#loading the scikit-learn's dataset
from sklearn import datasets

#Loading digits dataset from scikit-learn
digits=datasets.load_digits()

#Creating features matrix
features = digits.data

#Creating a target vector
target=digits.target
features[0]
#Problem---Create a dataset of simulated data
#Solution---Scikit-learn library offers many methods for creating simulated data.

#loading the linear_regression library
from sklearn.datasets import make_regression

#Generating features matrix,target vector, and the true coefficients

features,target,coefficients= make_regression(n_samples=100,
                                              n_features=3,
                                              n_informative=3,
                                              n_targets=1,
                                              noise=0.0,
                                              coef=True,
                                              random_state=1)                    
                                        
#returning Feature matrix
print(features[:5])
#returning target vector
print(target[:5])
#importing library for classification
from sklearn.datasets import make_classification

#Generating features matrix,and target vector
features,target= make_classification(n_samples=100,
                                     n_features=3,
                                     n_informative=3,
                                     n_redundant=0,
                                     n_classes =2,
                                     weights = [.25,.75],
                                     random_state=1)    
#returning feature matrix
print(features[:5])
#printing target vector
print(target[:5])
#import the make_blobs dataset
from sklearn.datasets import make_blobs

#Generating features matrix,and target vector
features,target=make_blobs(n_samples=100,
                          n_features=2,
                          centers =3,
                          cluster_std=0.5,
                          shuffle =True,
                          random_state = 1)
#printing features matrix
print(features[:5])
#Printing target vector
print(target[:5])
#we can view the clusters generated by make_blobs using matplotlib library

#importing matplotlib library
from matplotlib import pyplot as plt

#visualising the scatterplot of clusters
plt.scatter(features[:,0],features[:,1],c=target)
#Problem---Import a CSV file
#Solution---We will use panda's library to import csv file

#importing panda's library
import pandas as pd

#Creating the URL or address of the csv file
url = "https://support.staffbase.com/hc/en-us/article_attachments/360009197071/email.csv"

#Loading the dataset from the url
dataframe = pd.read_csv(url)
#Printing the first 2 rows
dataframe.head(2)
#printing the last 2 rows
dataframe.tail(2)
#Problem--- Import excel spreadsheet
#Solution---We will use panda's read_excel

#importing the library
import pandas as pd

#loading the excel file
dataframe=pd.read_excel("../input/publicassistance/SNAP_FY2010_FY2020/FY20.xls",header=1)

#printing the last 10 rows
dataframe.tail(3)
#Problem---Load the JSON file 
#Solution---We will use pandas's read_json

#importing pandas library
import pandas as pd

#loading the json file
dataframe=pd.read_json("../input/iris-dataset-json-version/iris.json",orient="columns")
#printing first 10 rows
dataframe.head(10)
#Problem---Load the data from the SQL databse
#Solution---We will use read_sql_query

#Importing the pandas library and sqlalchemy library for creating eingine
import pandas as pd
from sqlalchemy import create_engine

#The first step is to connect the database to the system.
#Creating a connection to the database
database_connection = create_engine('sqlite://', echo=False)

#Creating dataframe for converting to database
df = pd.DataFrame({'name' : ['User 1', 'User 2', 'User 3']})
df.to_sql('users', con=database_connection)


#Loading the data 
database_connection.execute("SELECT * FROM users").fetchall()
