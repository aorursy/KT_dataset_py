# Linear algebra

import numpy as np



# Data processing, CSV file I/O (e.g. pd.read_csv)

import pandas as pd



# Analyze data skewness

from scipy.stats import skew



# Label encoder

from sklearn.preprocessing import LabelEncoder



# Import Ensemble models

from sklearn.ensemble import RandomForestRegressor

from sklearn.ensemble import GradientBoostingRegressor

from sklearn.neural_network import MLPRegressor

from sklearn.linear_model import Ridge

from sklearn.linear_model import LinearRegression

from mlxtend.regressor import StackingRegressor



# Metrics for root mean squared error

from sklearn.metrics import mean_squared_error

from math import sqrt
# Load training data

df_train = pd.read_csv('../input/train.csv')



# Load test data

df_test = pd.read_csv('../input/test.csv')
# Remove outliers

df_train = df_train.drop(

    df_train[(df_train['GrLivArea']>4000) & (df_train['SalePrice']<300000)].index)
# Concatenate data

all_data = pd.concat((df_train.loc[:,'MSSubClass':'SaleCondition'],

                      df_test.loc[:,'MSSubClass':'SaleCondition']))
# Drop utilities column

all_data = all_data.drop(['Utilities'], axis=1)
# Impute missing categorical values

all_data["PoolQC"] = all_data["PoolQC"].fillna("None")

all_data["MiscFeature"] = all_data["MiscFeature"].fillna("None")

all_data["Alley"] = all_data["Alley"].fillna("None")

all_data["Fence"] = all_data["Fence"].fillna("None")

all_data["FireplaceQu"] = all_data["FireplaceQu"].fillna("None")

for col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):

    all_data[col] = all_data[col].fillna('None')

for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):

    all_data[col] = all_data[col].fillna('None')

all_data['MSZoning'] = all_data['MSZoning'].fillna(all_data['MSZoning'].mode()[0])

all_data["MasVnrType"] = all_data["MasVnrType"].fillna("None")

all_data["Functional"] = all_data["Functional"].fillna("Typ")

all_data['Electrical'] = all_data['Electrical'].fillna(all_data['Electrical'].mode()[0])

all_data['KitchenQual'] = all_data['KitchenQual'].fillna(all_data['KitchenQual'].mode()[0])

all_data['Exterior1st'] = all_data['Exterior1st'].fillna(all_data['Exterior1st'].mode()[0])

all_data['Exterior2nd'] = all_data['Exterior2nd'].fillna(all_data['Exterior2nd'].mode()[0])

all_data['SaleType'] = all_data['SaleType'].fillna(all_data['SaleType'].mode()[0])

all_data['MSSubClass'] = all_data['MSSubClass'].fillna("None")
# Group by neighborhood and fill in missing value by the median LotFrontage of all the neighborhood

all_data["LotFrontage"] = all_data.groupby("Neighborhood")["LotFrontage"].transform(

    lambda x: x.fillna(x.median()))



for col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):

    all_data[col] = all_data[col].fillna(0)

    

for col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):

    all_data[col] = all_data[col].fillna(0)

    

all_data["MasVnrArea"] = all_data["MasVnrArea"].fillna(0)
#MSSubClass=The building class

all_data['MSSubClass'] = all_data['MSSubClass'].apply(str)



#Changing OverallCond into a categorical variable

all_data['OverallCond'] = all_data['OverallCond'].astype(str)



#Year and month sold are transformed into categorical features.

all_data['YrSold'] = all_data['YrSold'].astype(str)

all_data['MoSold'] = all_data['MoSold'].astype(str)
# Adding total sqfootage feature 

all_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']
#log transform the target:

df_train["SalePrice"] = np.log1p(df_train["SalePrice"])
#log transform skewed numeric features:

numeric_feats = all_data.dtypes[all_data.dtypes != "object"].index



skewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna())) #compute skewness

skewed_feats = skewed_feats[skewed_feats > 0.75]

skewed_feats = skewed_feats.index



all_data[skewed_feats] = np.log1p(all_data[skewed_feats])
cols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', 

        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', 

        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',

        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', 

        'YrSold', 'MoSold')



# process columns, apply LabelEncoder to categorical features

for c in cols:

    lbl = LabelEncoder() 

    lbl.fit(list(all_data[c].values)) 

    all_data[c] = lbl.transform(list(all_data[c].values))
all_data = pd.get_dummies(all_data)
X_train = all_data[:df_train.shape[0]]

X_test = all_data[df_train.shape[0]:]



y = df_train.SalePrice
# Initialize models

lr = LinearRegression(

    n_jobs = -1

)



rd = Ridge(

    alpha = 4.84

)



rf = RandomForestRegressor(

    n_estimators = 12,

    max_depth = 3,

    n_jobs = -1

)



gb = GradientBoostingRegressor(

    n_estimators = 40,

    max_depth = 2

)



nn = MLPRegressor(

    hidden_layer_sizes = (90, 90),

    alpha = 2.75

)
# Initialize Ensemble

model = StackingRegressor(

    regressors=[rf, gb, nn, rd],

    meta_regressor=lr

)



# Fit the model on our data

model.fit(X_train, y)
# Predict training set

y_pred = model.predict(X_train)

print(sqrt(mean_squared_error(y, y_pred)))
# Predict test set

Y_pred = model.predict(X_test)
# Create empty submission dataframe

sub = pd.DataFrame()



# Insert ID and Predictions into dataframe

sub['Id'] = df_test['Id']

sub['SalePrice'] = np.expm1(Y_pred)



# Output submission file

sub.to_csv('submission.csv',index=False)