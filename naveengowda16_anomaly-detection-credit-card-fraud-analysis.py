#Import the required libraries



import numpy as np

import pandas as pd

import sklearn

import scipy

import matplotlib.pyplot as plt

import seaborn as sns

from sklearn.metrics import classification_report,accuracy_score

from sklearn.ensemble import IsolationForest

from sklearn.neighbors import LocalOutlierFactor

from sklearn.svm import OneClassSVM

from pylab import rcParams

rcParams['figure.figsize'] = 14, 8

RANDOM_SEED = 42

LABELS = ["Normal", "Fraud"]

import plotly.plotly as py

import plotly.graph_objs as go

import plotly

import plotly.figure_factory as ff

from plotly.offline import init_notebook_mode, iplot
data = pd.read_csv('../input/creditcard_data.csv')

data.head()
data1= data.sample(frac = 0.1,random_state=1)

data1.shape
# Checking the missing values 

data.isnull().sum()
data.describe()
#Determine the number of fraud and valid transactions in the entire dataset



count_classes = pd.value_counts(data['Class'], sort = True)

count_classes.plot(kind = 'bar', rot=0)

plt.title("Transaction Class Distribution")

plt.xticks(range(2), LABELS)

plt.xlabel("Class")

plt.ylabel("Frequency");
#Assigning the transaction class "0 = NORMAL  & 1 = FRAUD"

Normal = data[data['Class']==0]

Fraud = data[data['Class']==1]
Normal.shape
Fraud.shape
#How different are the amount of money used in different transaction classes?



Normal.Amount.describe()
#How different are the amount of money used in different transaction classes?



Fraud.Amount.describe()
#Let's have a more graphical representation of the data



f, (ax1, ax2) = plt.subplots(2, 1, sharex=True)

f.suptitle('Amount per transaction by class')

bins = 50

ax1.hist(Fraud.Amount, bins = bins)

ax1.set_title('Fraud')

ax2.hist(Normal.Amount, bins = bins)

ax2.set_title('Normal')

plt.xlabel('Amount ($)')

plt.ylabel('Number of Transactions')

plt.xlim((0, 20000))

plt.yscale('log')

plt.show();
#Graphical representation of the data



f, (ax1, ax2) = plt.subplots(2, 1, sharex=True)

f.suptitle('Time of transaction vs Amount by class')

ax1.scatter(Fraud.Time, Fraud.Amount)

ax1.set_title('Fraud')

ax2.scatter(Normal.Time, Normal.Amount)

ax2.set_title('Normal')

plt.xlabel('Time (in Seconds)')

plt.ylabel('Amount')

plt.show();
init_notebook_mode(connected=True)

plotly.offline.init_notebook_mode(connected=True)
# Create a trace



trace = go.Scatter(

    x = Fraud.Time,

    y = Fraud.Amount,

    mode = 'markers'

)

data = [trace]



plotly.offline.iplot({

    "data": data

})
data1.shape
#Determine the number of fraud and valid transactions in the dataset.



Fraud = data1[data1['Class']==1]

Valid = data1[data1['Class']==0]

outlier_fraction = len(Fraud)/float(len(Valid))
#Now let us print the outlier fraction and no of Fraud and Valid Transaction cases



print(outlier_fraction)

print("Fraud Cases : {}".format(len(Fraud)))

print("Valid Cases : {}".format(len(Valid)))
#Correlation Matrix



correlation_matrix = data1.corr()

fig = plt.figure(figsize=(12,9))

sns.heatmap(correlation_matrix,vmax=0.8,square = True)

plt.show()
#Get all the columns from the dataframe



columns = data1.columns.tolist()

# Filter the columns to remove data we do not want 

columns = [c for c in columns if c not in ["Class"]]

# Store the variable we are predicting 

target = "Class"

# Define a random state 

state = np.random.RandomState(42)

X = data1[columns]

Y = data1[target]

X_outliers = state.uniform(low=0, high=1, size=(X.shape[0], X.shape[1]))

# Print the shapes of X & Y

print(X.shape)

print(Y.shape)
#Define the outlier detection methods



classifiers = {

    "Isolation Forest":IsolationForest(n_estimators=100, max_samples=len(X), 

                                       contamination=outlier_fraction,random_state=state, verbose=0),

    "Local Outlier Factor":LocalOutlierFactor(n_neighbors=20, algorithm='auto', 

                                              leaf_size=30, metric='minkowski',

                                              p=2, metric_params=None, contamination=outlier_fraction),

    "Support Vector Machine":OneClassSVM(kernel='rbf', degree=3, gamma=0.1,nu=0.05, 

                                         max_iter=-1, random_state=state)

   

}
#Fit the model



n_outliers = len(Fraud)

for i, (clf_name,clf) in enumerate(classifiers.items()):

    #Fit the data and tag outliers

    if clf_name == "Local Outlier Factor":

        y_pred = clf.fit_predict(X)

        scores_prediction = clf.negative_outlier_factor_

    elif clf_name == "Support Vector Machine":

        clf.fit(X)

        y_pred = clf.predict(X)

    else:    

        clf.fit(X)

        scores_prediction = clf.decision_function(X)

        y_pred = clf.predict(X)

    #Reshape the prediction values to 0 for Valid transactions , 1 for Fraud transactions

    y_pred[y_pred == 1] = 0

    y_pred[y_pred == -1] = 1

    n_errors = (y_pred != Y).sum()

    # Run Classification Metrics

    print("{}: {}".format(clf_name,n_errors))

    print("Accuracy Score :")

    print(accuracy_score(Y,y_pred))

    print("Classification Report :")

    print(classification_report(Y,y_pred))