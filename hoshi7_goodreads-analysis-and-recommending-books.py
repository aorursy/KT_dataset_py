!pip install isbnlib

!pip install newspaper3k

!pip install goodreads_api_client


import numpy as np 

import pandas as pd

import os

import seaborn as sns

import isbnlib

from newspaper import Article

import matplotlib.pyplot as plt

plt.style.use('ggplot')

from tqdm import tqdm

from progressbar import ProgressBar

import re

from scipy.cluster.vq import kmeans, vq

from pylab import plot, show

from matplotlib.lines import Line2D

import matplotlib.colors as mcolors

import goodreads_api_client as gr

from sklearn.cluster import KMeans

from sklearn import neighbors

from sklearn.model_selection import train_test_split

from sklearn.preprocessing import MinMaxScaler

import warnings

warnings.filterwarnings("ignore")
df = pd.read_csv('../input/books.csv', error_bad_lines = False)



df.index = df['bookID']
#Finding Number of rows and columns

print("Dataset contains {} rows and {} columns".format(df.shape[0], df.shape[1]))

df.head()
df.replace(to_replace='J.K. Rowling-Mary GrandPrÃ©', value = 'J.K. Rowling', inplace=True)



df.head()
#Taking the first 20:



sns.set_context('poster')

plt.figure(figsize=(20,15))

books = df['title'].value_counts()[:20]

rating = df.average_rating[:20]

sns.barplot(x = books, y = books.index, palette='deep')

plt.title("Most Occurring Books")

plt.xlabel("Number of occurances")

plt.ylabel("Books")

plt.show()
sns.set_context('paper')

plt.figure(figsize=(15,10))

ax = df.groupby('language_code')['title'].count().plot.bar()

plt.title('Language Code')

plt.xticks(fontsize = 15)

for p in ax.patches:

    ax.annotate(str(p.get_height()), (p.get_x()-0.3, p.get_height()+100))
most_rated = df.sort_values('ratings_count', ascending = False).head(10).set_index('title')

plt.figure(figsize=(15,10))

sns.barplot(most_rated['ratings_count'], most_rated.index, palette='rocket')





sns.set_context('talk')

most_books = df.groupby('authors')['title'].count().reset_index().sort_values('title', ascending=False).head(10).set_index('authors')

plt.figure(figsize=(15,10))

ax = sns.barplot(most_books['title'], most_books.index, palette='icefire_r')

ax.set_title("Top 10 authors with most books")

ax.set_xlabel("Total number of books")

for i in ax.patches:

    ax.text(i.get_width()+.3, i.get_y()+0.5, str(round(i.get_width())), fontsize = 10, color = 'k')



client = gr.Client(developer_key= 'fgwnppR6Q1wpFt0n6umUQ') #If possible, please get your own? :)
# Creating a function to get book details from the ISBN 13 value.



#Alternate scraping solution, when both the API(s) fails

def html(isbn):

    url = 'https://isbndb.com/book/'+isbn

    article = Article(url)

    #article = 'https://isbndb.com/book/9780450524684'

    article.download()

    article.parse()

    ar = article.html

    ar = ar[9300:9900]

    return ar



def reg(l):

    return re.search(r'(\b\d{4})\b',l).groups()[0]

    

#Gathering the data for the year column for the books from their ISBN 13 values

def bookdata(df):

    year=[]

    pbar = ProgressBar()

    for isbn in pbar(df.isbn13):

        try:

            details = isbnlib.meta(isbn)

            year.append(details['Year'])

        except :

            #Trying out with goodreads api now

            try: 

                book_detail = client.Book.show_by_isbn(isbn)

                keys_wanted = ['publication_year']

                reduced_book = {k:v for k,v in book_detail.items() if k in keys_wanted}

                year.append((reduced_book['publication_year']))

            

            except: 

                #Going with webscraping

                try:

                    y = html(isbn)

                    year_extracted = reg(y) #Extracting year with regex

                    year.append(y)

                except:

                    year.append('0')

                

    return year



def plot_author_chart(author_df):

    year = bookdata(author_df)

    author_df = final_df(author_df, year)

    author_df.dropna(0, inplace=True)

    author_df = author_df[author_df['Year'].str.isnumeric()]

    author_df = author_df.set_index('title')

    author_df = author_df[author_df.Year !='0']

    plt.figure(figsize=(15,15))

    sns.set_context('talk')

    plt.xticks(rotation=30)

    ax =  sns.barplot( author_df['Year'], author_df['average_rating'], palette='deep')

    ax.set_title("Average rating of books over time, "+ author_df.authors[1])

    plt.xticks(rotation=30)

    return ax







# The finction for getting the final dataframe for the charts

def final_df(df1, l):

    year_df = pd.DataFrame(l, columns=['Year'])

    df1 = df1.reset_index(drop=True)

    final = df1[['authors', 'average_rating', 'title']].join(year_df)

    return final
#Finding the top 15 authors with the most number of books

df['authors'].value_counts().head(10)
authors= ['Stephen King', 'Agatha Christie', 'Dan Brown', 'J.K. Rowling']
author_df = df[df['authors']==authors[0]]

author_df = author_df[author_df['language_code']=='eng']

plot_author_chart(author_df)
author_df = df[df['authors']==authors[1]]

author_df = author_df[author_df['language_code']=='eng']

plot_author_chart(author_df)
author_df = df[df['authors']==authors[2]]

author_df = author_df[author_df['language_code']=='eng']

plot_author_chart(author_df)
author_df = df[df['authors']==authors[3]]

author_df = author_df[author_df['language_code']=='eng']

plot_author_chart(author_df)





high_rated_author = df[df['average_rating']>=4.3]

high_rated_author = high_rated_author.groupby('authors')['title'].count().reset_index().sort_values('title', ascending = False).head(10).set_index('authors')

plt.figure(figsize=(15,10))

ax = sns.barplot(high_rated_author['title'], high_rated_author.index, palette='Set2')

ax.set_xlabel("Number of Books")

ax.set_ylabel("Authors")

for i in ax.patches:

    ax.text(i.get_width()+.3, i.get_y()+0.5, str(round(i.get_width())), fontsize = 10, color = 'k')









def segregation(data):

    values = []

    for val in data.average_rating:

        if val>=0 and val<=1:

            values.append("Between 0 and 1")

        elif val>1 and val<=2:

            values.append("Between 1 and 2")

        elif val>2 and val<=3:

            values.append("Between 2 and 3")

        elif val>3 and val<=4:

            values.append("Between 3 and 4")

        elif val>4 and val<=5:

            values.append("Between 4 and 5")

        else:

            values.append("NaN")

    print(len(values))

    return values
df.average_rating.isnull().value_counts()
df.dropna(0, inplace=True)

#Removing Any null values
plt.figure(figsize=(10,10))

rating= df.average_rating.astype(float)

sns.distplot(rating, bins=20)



df['Ratings_Dist'] = segregation(df)

ratings_pie = df['Ratings_Dist'].value_counts().reset_index()

labels = ratings_pie['index']

colors = ['lightblue','darkmagenta','coral','bisque', 'black']

percent = 100.*ratings_pie['Ratings_Dist']/ratings_pie['Ratings_Dist'].sum()

fig, ax1 = plt.subplots()

ax1.pie(ratings_pie['Ratings_Dist'],colors = colors, 

        pctdistance=0.85, startangle=90, explode=(0.05, 0.05, 0.05, 0.05, 0.05))

#Draw a circle now:

centre_circle = plt.Circle((0,0), 0.70, fc ='white')

fig1 = plt.gcf()

fig1.gca().add_artist(centre_circle)

#Equal Aspect ratio ensures that pie is drawn as a circle

plt.axis('equal')

plt.tight_layout()

labels = ['{0} - {1:1.2f} %'.format(i,j) for i,j in zip(labels, percent)]

plt.legend( labels, loc = 'best',bbox_to_anchor=(-0.1, 1.),)



#Checking for any relation between them.

plt.figure(figsize=(15,10))

df.dropna(0, inplace=True)

sns.set_context('paper')

ax =sns.jointplot(x="average_rating",y='text_reviews_count', kind='scatter',  data= df[['text_reviews_count', 'average_rating']])

ax.set_axis_labels("Average Rating", "Text Review Count")

plt.show()



trial = df[~(df['text_reviews_count']>5000)]
#Checking for any relation between them.

plt.figure(figsize=(15,10))

df.dropna(0, inplace=True)

sns.set_context('paper')

ax =sns.jointplot(x="average_rating",y='text_reviews_count', kind='scatter',  data= trial, color = 'green')

ax.set_axis_labels("Average Rating", "Text Review Count")

plt.show()



plt.figure(figsize=(15,10))

sns.set_context('paper')

ax = sns.jointplot(x="average_rating", y="# num_pages", data = df, color = 'crimson')

ax.set_axis_labels("Average Rating", "Number of Pages")

trial = df[~(df['# num_pages']>1000)]
ax = sns.jointplot(x="average_rating", y="# num_pages", data = trial, color = 'darkcyan')

ax.set_axis_labels("Average Rating", "Number of Pages")

sns.set_context('paper')

ax = sns.jointplot(x="average_rating", y="ratings_count", data = df, color = 'blueviolet')

ax.set_axis_labels("Average Rating", "Ratings Count")

trial = df[~(df.ratings_count>2000000)]
sns.set_context('paper')

ax = sns.jointplot(x="average_rating", y="ratings_count", data = trial, color = 'brown')

ax.set_axis_labels("Average Rating", "Ratings Count")

most_text = df.sort_values('text_reviews_count', ascending = False).head(10).set_index('title')

plt.figure(figsize=(15,10))

sns.set_context('poster')

ax = sns.barplot(most_text['text_reviews_count'], most_text.index, palette='magma')

for i in ax.patches:

    ax.text(i.get_width()+2, i.get_y()+0.5,str(round(i.get_width())), fontsize=10,color='black')

plt.show()





trial = df[['average_rating', 'ratings_count']]

data = np.asarray([np.asarray(trial['average_rating']), np.asarray(trial['ratings_count'])]).T



X = data

distortions = []

for k in range(2,30):

    k_means = KMeans(n_clusters = k)

    k_means.fit(X)

    distortions.append(k_means.inertia_)



fig = plt.figure(figsize=(15,10))

plt.plot(range(2,30), distortions, 'bx-')

plt.title("Elbow Curve")
#Computing K means with K = 5, thus, taking it as 5 clusters

centroids, _ = kmeans(data, 5)



#assigning each sample to a cluster

#Vector Quantisation:



idx, _ = vq(data, centroids)
# some plotting using numpy's logical indexing

sns.set_context('paper')

plt.figure(figsize=(15,10))

plt.plot(data[idx==0,0],data[idx==0,1],'or',#red circles

     data[idx==1,0],data[idx==1,1],'ob',#blue circles

     data[idx==2,0],data[idx==2,1],'oy', #yellow circles

     data[idx==3,0],data[idx==3,1],'om', #magenta circles

     data[idx==4,0],data[idx==4,1],'ok',#black circles

    

     

        

        

        

        

        )

plt.plot(centroids[:,0],centroids[:,1],'sg',markersize=8, )









circle1 = Line2D(range(1), range(1), color = 'red', linewidth = 0, marker= 'o', markerfacecolor='red')

circle2 = Line2D(range(1), range(1), color = 'blue', linewidth = 0,marker= 'o', markerfacecolor='blue')

circle3 = Line2D(range(1), range(1), color = 'yellow',linewidth=0,  marker= 'o', markerfacecolor='yellow')

circle4 = Line2D(range(1), range(1), color = 'magenta', linewidth=0,marker= 'o', markerfacecolor='magenta')

circle5 = Line2D(range(1), range(1), color = 'black', linewidth = 0,marker= 'o', markerfacecolor='black')



plt.legend((circle1, circle2, circle3, circle4, circle5)

           , ('Cluster 1','Cluster 2', 'Cluster 3', 'Cluster 4', 'Cluster 5'), numpoints = 1, loc = 0, )





plt.show()
trial.idxmax()
trial.drop(3, inplace = True)

trial.drop(41865, inplace = True)
data = np.asarray([np.asarray(trial['average_rating']), np.asarray(trial['ratings_count'])]).T





#Computing K means with K = 8, thus, taking it as 8 clusters

centroids, _ = kmeans(data, 5)



#assigning each sample to a cluster

#Vector Quantisation:



idx, _ = vq(data, centroids)
# some plotting using numpy's logical indexing

sns.set_context('paper')

plt.figure(figsize=(15,10))

plt.plot(data[idx==0,0],data[idx==0,1],'or',#red circles

     data[idx==1,0],data[idx==1,1],'ob',#blue circles

     data[idx==2,0],data[idx==2,1],'oy', #yellow circles

     data[idx==3,0],data[idx==3,1],'om', #magenta circles

     data[idx==4,0],data[idx==4,1],'ok',#black circles

    

     

        

        

        

        

        )

plt.plot(centroids[:,0],centroids[:,1],'sg',markersize=8, )









circle1 = Line2D(range(1), range(1), color = 'red', linewidth = 0, marker= 'o', markerfacecolor='red')

circle2 = Line2D(range(1), range(1), color = 'blue', linewidth = 0,marker= 'o', markerfacecolor='blue')

circle3 = Line2D(range(1), range(1), color = 'yellow',linewidth=0,  marker= 'o', markerfacecolor='yellow')

circle4 = Line2D(range(1), range(1), color = 'magenta', linewidth=0,marker= 'o', markerfacecolor='magenta')

circle5 = Line2D(range(1), range(1), color = 'black', linewidth = 0,marker= 'o', markerfacecolor='black')



plt.legend((circle1, circle2, circle3, circle4, circle5)

           , ('Cluster 1','Cluster 2', 'Cluster 3', 'Cluster 4', 'Cluster 5'), numpoints = 1, loc = 0, )





plt.show()
books_features = pd.concat([df['Ratings_Dist'].str.get_dummies(sep=","), df['average_rating'], df['ratings_count']], axis=1)
books_features.head()
min_max_scaler = MinMaxScaler()

books_features = min_max_scaler.fit_transform(books_features)
np.round(books_features, 2)
model = neighbors.NearestNeighbors(n_neighbors=6, algorithm='ball_tree')

model.fit(books_features)

distance, indices = model.kneighbors(books_features)



def get_index_from_name(name):

    return df[df["title"]==name].index.tolist()[0]



all_books_names = list(df.title.values)



def get_id_from_partial_name(partial):

    for name in all_books_names:

        if partial in name:

            print(name,all_books_names.index(name))

            

def print_similar_books(query=None,id=None):

    if id:

        for id in indices[id][1:]:

            print(df.iloc[id]["title"])

    if query:

        found_id = get_index_from_name(query)

        for id in indices[found_id][1:]:

            print(df.iloc[id]["title"])
print_similar_books("The Catcher in the Rye")

print_similar_books("The Hobbit or There and Back Again")
get_id_from_partial_name("Harry Potter and the ")
print_similar_books(id = 1) #ID for the Book 5