# Import libraries and set desired options

import os

import pickle

import numpy as np

import pandas as pd

from scipy.sparse import hstack

# !pip install eli5

import eli5

from sklearn.feature_extraction.text import TfidfVectorizer

from sklearn.preprocessing import StandardScaler

from sklearn.model_selection import TimeSeriesSplit, cross_val_score, GridSearchCV

from sklearn.metrics import roc_auc_score

from sklearn.linear_model import LogisticRegression

from matplotlib import pyplot as plt

import seaborn as sns

from IPython.display import display_html
PATH_TO_DATA = '../input/'

SEED = 17
def prepare_sparse_features(path_to_train, path_to_test, path_to_site_dict,

                           vectorizer_params):

    times = ['time%s' % i for i in range(1, 11)]

    train_df = pd.read_csv(path_to_train,

                       index_col='session_id', parse_dates=times)

    test_df = pd.read_csv(path_to_test,

                      index_col='session_id', parse_dates=times)



    # Sort the data by time

    train_df = train_df.sort_values(by='time1')

    

    # read site -> id mapping provided by competition organizers 

    with open(path_to_site_dict, 'rb') as f:

        site2id = pickle.load(f)

    # create an inverse id _> site mapping

    id2site = {v:k for (k, v) in site2id.items()}

    # we treat site with id 0 as "unknown"

    id2site[0] = 'unknown'

    

    # Transform data into format which can be fed into TfidfVectorizer

    # This time we prefer to represent sessions with site names, not site ids. 

    # It's less efficient but thus it'll be more convenient to interpret model weights.

    sites = ['site%s' % i for i in range(1, 11)]

    train_sessions = train_df[sites].fillna(0).astype('int').apply(lambda row: 

                                                     ' '.join([id2site[i] for i in row]), axis=1).tolist()

    test_sessions = test_df[sites].fillna(0).astype('int').apply(lambda row: 

                                                     ' '.join([id2site[i] for i in row]), axis=1).tolist()

    # we'll tell TfidfVectorizer that we'd like to split data by whitespaces only 

    # so that it doesn't split by dots (we wouldn't like to have 'mail.google.com' 

    # to be split into 'mail', 'google' and 'com')

    vectorizer = TfidfVectorizer(**vectorizer_params)

    X_train = vectorizer.fit_transform(train_sessions)

    X_test = vectorizer.transform(test_sessions)

    y_train = train_df['target'].astype('int').values

    

    # we'll need site visit times for further feature engineering

    train_times, test_times = train_df[times], test_df[times]

    

    return X_train, X_test, y_train, vectorizer, train_times, test_times
%%time

X_train_sites, X_test_sites, y_train, vectorizer, train_times, test_times = prepare_sparse_features(

    path_to_train=os.path.join(PATH_TO_DATA, 'train_sessions.csv'),

    path_to_test=os.path.join(PATH_TO_DATA, 'test_sessions.csv'),

    path_to_site_dict=os.path.join(PATH_TO_DATA, 'site_dic.pkl'),

    vectorizer_params={'ngram_range': (1, 5), 

                       'max_features': 50000,

                       'tokenizer': lambda s: s.split()}

)
print(X_train_sites.shape, X_test_sites.shape)
vectorizer.get_feature_names()[:10]
vectorizer.get_feature_names()[10000:10010]
time_split = TimeSeriesSplit(n_splits=10)
logit = LogisticRegression(C=1, random_state=SEED, solver='liblinear')
%%time



cv_scores1 = cross_val_score(logit, X_train_sites, y_train, cv=time_split, 

                            scoring='roc_auc', n_jobs=4) # hangs with n_jobs > 1, and locally this runs much faster
cv_scores1, cv_scores1.mean()
logit.fit(X_train_sites, y_train)
eli5.show_weights(estimator=logit, 

                  feature_names=vectorizer.get_feature_names(), top=30)
# A helper function for writing predictions to a file

def write_to_submission_file(predicted_labels, out_file,

                             target='target', index_label="session_id"):

    predicted_df = pd.DataFrame(predicted_labels,

                                index = np.arange(1, predicted_labels.shape[0] + 1),

                                columns=[target])

    predicted_df.to_csv(out_file, index_label=index_label)
logit_test_pred = logit.predict_proba(X_test_sites)[:, 1]

write_to_submission_file(logit_test_pred, 'subm1.csv') # 0.91807
def train_and_predict(model, X_train, y_train, X_test, site_feature_names=vectorizer.get_feature_names(), 

                      new_feature_names=None, cv=time_split, scoring='roc_auc',

                      top_n_features_to_show=30, submission_file_name='submission.csv'):

    

    

    cv_scores = cross_val_score(model, X_train, y_train, cv=cv, 

                            scoring=scoring, n_jobs=4)

    print('CV scores', cv_scores)

    print('CV mean: {}, CV std: {}'.format(cv_scores.mean(), cv_scores.std()))

    model.fit(X_train, y_train)

    

    if new_feature_names:

        all_feature_names = site_feature_names + new_feature_names 

    else: 

        all_feature_names = site_feature_names

    

    display_html(eli5.show_weights(estimator=model, 

                  feature_names=all_feature_names, top=top_n_features_to_show))

    

    if new_feature_names:

        print('New feature weights:')

    

        print(pd.DataFrame({'feature': new_feature_names, 

                        'coef': model.coef_.flatten()[-len(new_feature_names):]}))

    

    test_pred = model.predict_proba(X_test)[:, 1]

    write_to_submission_file(test_pred, submission_file_name) 

    

    return cv_scores
cv_scores1 = train_and_predict(model=logit, X_train=X_train_sites, y_train=y_train, 

                  X_test=X_test_sites, site_feature_names=vectorizer.get_feature_names(),              

                  cv=time_split, submission_file_name='subm1.csv')
session_start_hour = train_times['time1'].apply(lambda ts: ts.hour).values
sns.countplot(session_start_hour);
plt.subplots(1, 2, figsize = (12, 6)) 



plt.subplot(1, 2, 1)

sns.countplot(session_start_hour[y_train == 1])

plt.title("Alice")

plt.xlabel('Session start hour')

          

plt.subplot(1, 2, 2)

sns.countplot(session_start_hour[y_train == 0])

plt.title('Others')

plt.xlabel('Session start hour');
morning = ((session_start_hour >= 7) & (session_start_hour <= 11)).astype('int')

day = ((session_start_hour >= 12) & (session_start_hour <= 18)).astype('int')

evening = ((session_start_hour >= 19) & (session_start_hour <= 23)).astype('int')

night = ((session_start_hour >= 0) & (session_start_hour <= 6)).astype('int')
pd.crosstab([morning, day, evening, night], y_train, rownames=['morning', 'day', 'evening', 'night'])
def add_time_features(times, X_sparse, add_hour=True):

    hour = times['time1'].apply(lambda ts: ts.hour)

    morning = ((hour >= 7) & (hour <= 11)).astype('int').values.reshape(-1, 1)

    day = ((hour >= 12) & (hour <= 18)).astype('int').values.reshape(-1, 1)

    evening = ((hour >= 19) & (hour <= 23)).astype('int').values.reshape(-1, 1)

    night = ((hour >= 0) & (hour <=6)).astype('int').values.reshape(-1, 1)

    

    objects_to_hstack = [X_sparse, morning, day, evening, night]

    feature_names = ['morning', 'day', 'evening', 'night']

    

    if add_hour:

        # we'll do it right and scale hour dividing by 24

        objects_to_hstack.append(hour.values.reshape(-1, 1) / 24)

        feature_names.append('hour')

        

    X = hstack(objects_to_hstack)

    return X, feature_names
%%time

X_train_with_times1, new_feat_names = add_time_features(train_times, X_train_sites)

X_test_with_times1, _ = add_time_features(test_times, X_test_sites)
X_train_with_times1.shape, X_test_with_times1.shape
cv_scores2 = train_and_predict(model=logit, X_train=X_train_with_times1, y_train=y_train, 

                               X_test=X_test_with_times1, 

                               site_feature_names=vectorizer.get_feature_names(),

                               new_feature_names=new_feat_names,

                               cv=time_split, submission_file_name='subm2.csv')
cv_scores2 > cv_scores1
%%time

X_train_with_times2, new_feat_names = add_time_features(train_times, X_train_sites, add_hour=False)

X_test_with_times2, _ = add_time_features(test_times, X_test_sites, add_hour=False)





cv_scores3 = train_and_predict(model=logit, X_train=X_train_with_times2, y_train=y_train, 

                               X_test=X_test_with_times2, 

                               site_feature_names=vectorizer.get_feature_names(),

                               new_feature_names=new_feat_names,

                               cv=time_split, submission_file_name='subm3.csv')
cv_scores3 > cv_scores1
cv_scores3 > cv_scores2
def add_session_duration_incorrect(times, X_sparse):

    new_feat = (times.max(axis=1) - times.min(axis=1)).astype('timedelta64[ms]').astype(int)

    return hstack([X_sparse, new_feat.values.reshape(-1, 1)])
X_train_with_time_incorrect = add_session_duration_incorrect(train_times, X_train_with_times2)

X_test_with_time_incorrect = add_session_duration_incorrect(test_times, X_test_with_times2)
cv_scores4 = train_and_predict(model=logit, X_train=X_train_with_time_incorrect, y_train=y_train, 

                               X_test=X_test_with_time_incorrect, 

                               site_feature_names=vectorizer.get_feature_names(),

                               new_feature_names=new_feat_names + ['sess_duration'],

                               cv=time_split, submission_file_name='subm4.csv')
train_durations = (train_times.max(axis=1) - train_times.min(axis=1)).astype('timedelta64[ms]').astype(int)

test_durations = (test_times.max(axis=1) - test_times.min(axis=1)).astype('timedelta64[ms]').astype(int)



scaler = StandardScaler()

train_dur_scaled = scaler.fit_transform(train_durations.values.reshape(-1, 1))

test_dur_scaled = scaler.transform(test_durations.values.reshape(-1, 1))
X_train_with_time_correct = hstack([X_train_with_times2, train_dur_scaled])

X_test_with_time_correct = hstack([X_test_with_times2, test_dur_scaled])
cv_scores5 = train_and_predict(model=logit, X_train=X_train_with_time_correct, y_train=y_train, 

                               X_test=X_test_with_time_correct, 

                               site_feature_names=vectorizer.get_feature_names(),

                               new_feature_names=new_feat_names + ['sess_duration'],

                               cv=time_split, submission_file_name='subm5.csv')
cv_scores5 > cv_scores3
def add_day_month(times, X_sparse):

    day_of_week = times['time1'].apply(lambda t: t.weekday()).values.reshape(-1, 1)

    month = times['time1'].apply(lambda t: t.month).values.reshape(-1, 1) 

    # linear trend: time in a form YYYYMM, we'll divide by 1e5 to scale this feature 

    year_month = times['time1'].apply(lambda t: 100 * t.year + t.month).values.reshape(-1, 1) / 1e5

    

    objects_to_hstack = [X_sparse, day_of_week, month, year_month]

    feature_names = ['day_of_week', 'month', 'year_month']

        

    X = hstack(objects_to_hstack)

    return X, feature_names
X_train_final, more_feat_names = add_day_month(train_times, X_train_with_time_correct)

X_test_final, _ = add_day_month(test_times, X_test_with_time_correct)
cv_scores6 = train_and_predict(model=logit, X_train=X_train_final, y_train=y_train, 

                               X_test=X_test_final, 

                               site_feature_names=vectorizer.get_feature_names(),

                               new_feature_names=new_feat_names + ['sess_duration'] + more_feat_names,

                               cv=time_split, submission_file_name='subm6.csv')
# here we've already narrowed down c_values to such a range.

# typically, you would start with a wider range of values to check

c_values = np.logspace(-2, 2, 20)



logit_grid_searcher = GridSearchCV(estimator=logit, param_grid={'C': c_values},

                                  scoring='roc_auc', n_jobs=4, cv=time_split, verbose=1)
%%time

logit_grid_searcher.fit(X_train_final, y_train); 
logit_grid_searcher.best_score_, logit_grid_searcher.best_params_
final_model = logit_grid_searcher.best_estimator_
cv_scores7 = train_and_predict(model=final_model, X_train=X_train_final, y_train=y_train, 

                               X_test=X_test_final, 

                               site_feature_names=vectorizer.get_feature_names(),

                               new_feature_names=new_feat_names + ['sess_duration'] + more_feat_names,

                               cv=time_split, submission_file_name='subm7.csv')
cv_scores7 > cv_scores6
cv_means = [np.round(cv_scores.mean(), 5) for cv_scores in [cv_scores1, cv_scores2, cv_scores3,

                                                                 cv_scores4, cv_scores5, cv_scores6, cv_scores7]]

cv_stds = [np.round(cv_scores.std(), 5) for cv_scores in [cv_scores1, cv_scores2, cv_scores3,

                                                                 cv_scores4, cv_scores5, cv_scores6, cv_scores7]]

public_lb_scores = [0.91807, 0.93135, 0.94526, 0.67016, 0.94620, 0.95061, 0.95055]



subm_df = pd.DataFrame({'CV_mean': cv_means, 'CV_std': cv_stds, 'LB': public_lb_scores},

                      index=range(1, len(cv_means) + 1))

subm_df
subm_df['cv_lb_weighted'] =  0.6 * subm_df['LB'] + (1 - 0.6) * subm_df['CV_mean']

subm_df
# so we'll treat the last submission as the best one

!cp subm7.csv submission.csv