import pandas as pd 
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix,precision_recall_fscore_support, auc
import warnings
warnings.filterwarnings('ignore')
dataset=pd.read_csv('../input/tidyHARdata.csv')
dataset.drop(dataset.columns[0], axis=1, inplace=True)
dataset.head(10)
print (f'Number of features = {len(dataset.columns)}')
print (f'Number of labels = {dataset.Activity.nunique()}')
print (f'Labels : {dataset.Activity.unique()}')
# Split data into X and y
X = dataset[dataset.columns[:-1]] ## Remove SubjectID and Activity 
Y = dataset[dataset.columns[-1]]

# split data into train and test sets
seed = 40
test_size = 0.33
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)
# fit model no training data
model = XGBClassifier(n_jobs=2) # using two processors 
model.fit(X_train, y_train)

from sklearn.feature_selection import SelectFromModel
sfm = SelectFromModel(model, prefit=True)
X_train_new = sfm.transform(X_train)
X_test_new = sfm.transform(X_test)

print("Original num features: {}, selected num features: {}"
      .format(X_train.shape[1], X_train_new.shape[1]))
import numpy as np
indices = np.argsort(model.feature_importances_)[::-1]
for idx, i in enumerate(indices):
    print("{}.\t{} - {}".format(idx, X_train.columns[i], model.feature_importances_[i]))
### Retrain on the important features
# fit model no training data
model = XGBClassifier(n_jobs=2) # using two processors 
model.fit(X_train_new, y_train)

# make predictions for test data
y_pred = model.predict(X_test_new)
y_pred_prop = model.predict_proba(X_test_new)
#predictions = [round(value) for value in y_pred_prop]
predictions=y_pred.copy()
# Confusion matrix
conf= confusion_matrix(y_test, predictions)

Labels=list(dataset.Activity.unique())
pd.DataFrame(conf,columns=Labels, index=Labels)
### precsion, recall, fscore, support 
pr_rec_f_supp=precision_recall_fscore_support(y_test, predictions)
DF_report=pd.DataFrame({'Precision':list(pr_rec_f_supp[0]),
                        'Recall':list(pr_rec_f_supp[1]),
                        'F-Score':list(pr_rec_f_supp[2]),
                        'Support':list(pr_rec_f_supp[3])}, index=Labels)
DF_report
### ROC and AUC 

#!pip install scikit-plot
import scikitplot as skplt
import matplotlib.pyplot as plt
plt.figure(figsize=(20,20))
y_true = y_test# ground truth labels
y_probas =y_pred_prop # predicted probabilities generated by sklearn classifier
skplt.metrics.plot_roc_curve(y_true, y_probas)
plt.show()

### ROC_AUC
import numpy as np
import matplotlib.pyplot as plt
from itertools import cycle

from sklearn import svm, datasets
from sklearn.metrics import roc_curve, auc
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import label_binarize
from sklearn.multiclass import OneVsRestClassifier
from scipy import interp

# Binarize the output
y = label_binarize(Y, classes=Labels)
n_classes = y.shape[1] # Number of classes 

# Add noisy features to make the problem harder
#random_state = np.random.RandomState(0)
#n_samples, n_features = X.shape
#X = np.c_[X, random_state.randn(n_samples, 200 * n_features)]

# shuffle and split training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5,
                                                    random_state=0)


# Learn to predict each class against the other
model = XGBClassifier(n_jobs=10)
classifier = OneVsRestClassifier(model)
y_score = classifier.fit(X_train, y_train).predict(X_test)

# Compute ROC curve and ROC area for each class
fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Compute micro-average ROC curve and ROC area
fpr["micro"], tpr["micro"], _ = roc_curve(y_test.ravel(), y_score.ravel())
roc_auc["micro"] = auc(fpr["micro"], tpr["micro"])
roc_auc


