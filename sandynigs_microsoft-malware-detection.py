#All imports here.

import warnings

warnings.filterwarnings("ignore")

import pandas as pd

import numpy as np

import matplotlib

import matplotlib.pyplot as plt

%matplotlib nbagg 

#Much larger, clear plots

import seaborn as sns



from tqdm import tqdm



from sklearn.manifold import TSNE

from sklearn.model_selection import train_test_split

from sklearn.metrics import log_loss

from sklearn.metrics import confusion_matrix



from sklearn.calibration import CalibratedClassifierCV

from sklearn.neighbors import KNeighborsClassifier

from sklearn.linear_model import LogisticRegression



from xgboost import XGBClassifier

from sklearn.model_selection import RandomizedSearchCV

from sklearn.tree import DecisionTreeClassifier

from sklearn.ensemble import RandomForestClassifier

class_labels = pd.read_csv("../input/trainLabels.csv")  #This will remain same for both asm or byte file.
#Statistical study of data.



dist_of_class = class_labels["Class"].value_counts()

dist_of_class = dist_of_class.apply( lambda x: ((x/sum(dist_of_class))*(100.0)) )

dist_of_class
total = len(class_labels)*1

#print(total)

ax = sns.countplot(x = "Class", data = class_labels)

"""

Documentation of sns.countplot here.

"""

for p in ax.patches:

    """ax.patches gives a list of rectangle object. Each element represent a rectangle in above histogram.

    Example: Rectangle(xy=(-0.4, 0), width=0.8, height=1541, angle=0)"""

    ax.annotate('{:.1f}%'.format(100*p.get_height()/total), (p.get_x()+0.1, p.get_height()+5))



#put 11 ticks (therefore 10 steps), from 0 to the total number of rows in the dataframe

ax.yaxis.set_ticks(np.linspace(0, total, 11))

#adjust the ticklabel to the desired format, without changing the position of the ticks. 

ax.set_yticklabels(map('{:.1f}%'.format, 100*ax.yaxis.get_majorticklocs()/total))

plt.show()
byte_file_size = pd.read_csv("../input/byte_file_size.csv")

byte_file_size.head()
ax = sns.boxplot(x = "Class", y="fsize", data= byte_file_size)

plt.title("boxplot of .byte file size")
byte_final_data = pd.read_csv("../input/byte_final_data.csv")

byte_final_data.head()
#Let's normalize the data.

def normalize(dataframe):

    #print("Here")

    test = dataframe.copy()

    for col in test.columns:

        if(col != "Id" and col !="Class"):

            max_val = max(dataframe[col])

            min_val = min(dataframe[col])

            test[col] = (dataframe[col] - min_val) / (max_val-min_val)

    return test
'''

test = byte_final_data

Above assignment will only make a new pointer of name test to byte_final_data dataframe object.

Any change performed will bring changes to both. Hence it is neccessary to create a new copy of df.

for col in test.columns:

    if (col != "Id" and col != "Class"):

        test[col] = test[col]+2

'''
byte_result = normalize(byte_final_data)

byte_result.head()
data_y = byte_result["Class"]
#With perplexity 50.

model = TSNE(perplexity = 50)

byte_tsne_data = model.fit_transform(byte_result.drop(["Id", "Class"], axis=1))
#Byte tsne data will return 2-dimesnions.

x_ax = byte_tsne_data[:,0]

y_ax = byte_tsne_data[:,1]

plt.scatter(x_ax, y_ax, c=data_y, cmap=plt.cm.get_cmap("jet", 9)) #cmap argument gives different color coded map.

plt.colorbar(ticks=range(10))

plt.clim(0.5, 9)

plt.show()
#With perplexity 30.

model = TSNE(perplexity = 30)

byte_tsne_data = model.fit_transform(byte_result.drop(["Id", "Class"], axis=1))
#Byte tsne data will return 2-dimesnions.

x_ax = byte_tsne_data[:,0]

y_ax = byte_tsne_data[:,1]

plt.scatter(x_ax, y_ax, c=data_y, cmap=plt.cm.get_cmap("jet", 9)) #cmap argument gives different color coded map.

plt.colorbar(ticks=range(10))

plt.clim(0.5, 9)

plt.show()
# split the data into test and train by maintaining same distribution of output varaible .[stratify=data_y]

x_train,x_test,y_train,y_test = train_test_split(byte_result.drop(["Id", "Class"],axis=1),data_y,stratify=data_y,test_size=0.20)

# split the data into train and cv by maintaining same distribution of output varaible. [stratify=y_train]

x_train,x_cv,y_train,y_cv = train_test_split(x_train,y_train,stratify=y_train,test_size=0.20)
#Training dataframe.

print("The shape of training dataframe is ", x_train.shape)



#Here we have y_train a series, and not a dataframe.

class_dist = y_train.value_counts()

class_dist = class_dist.apply(lambda x: (x/sum(class_dist))*(100.0))

class_dist 
#Training dataframe.

print("The shape of training dataframe is ", x_cv.shape)



#Here we have y_train a series, and not a dataframe.

class_dist = y_cv.value_counts()

class_dist = class_dist.apply(lambda x: (x/sum(class_dist))*(100.0))

class_dist
#Training dataframe.

print("The shape of training dataframe is ", x_test.shape)



#Here we have y_train a series, and not a dataframe.

class_dist = y_test.value_counts()

class_dist = class_dist.apply(lambda x: (x/sum(class_dist))*(100.0))

class_dist
#sort_index method will sort the series according to index (class labels here).

train_class_distribution = y_train.value_counts().sort_index()

cv_class_distribution = y_cv.value_counts().sort_index()

test_class_distribution = y_test.value_counts().sort_index()



train_class_distribution_list = list(train_class_distribution)

for i in range (0,9):

    print("Number of points in class", i+1,"are", train_class_distribution_list[i],'(',train_class_distribution_list[i]/ sum(train_class_distribution_list) * (100.0), '%)')



ax = sns.barplot(train_class_distribution.index, train_class_distribution.values)

ax.set_title("Distribution of y in train data")

ax.set_ylabel("Data points count")

ax.set_xlabel("Class")
cv_class_distribution_list = list(cv_class_distribution)

for i in range (0,9):

    print("Number of points in class", i+1,"are", cv_class_distribution_list[i],'(',cv_class_distribution_list[i]/ sum(cv_class_distribution_list) * (100.0), '%)')



ax = sns.barplot(cv_class_distribution.index, cv_class_distribution.values)

ax.set_title("Distribution of y in cv data")

ax.set_ylabel("Data points count")

ax.set_xlabel("Class")
test_class_distribution_list = list(test_class_distribution)

for i in range (0,9):

    print("Number of points in class", i+1,"are", test_class_distribution_list[i],'(',test_class_distribution_list[i]/ sum(test_class_distribution_list) * (100.0), '%)')



ax = sns.barplot(test_class_distribution.index, test_class_distribution.values)

ax.set_title("Distribution of y in test data")

ax.set_ylabel("Data points count")

ax.set_xlabel("Class")
def plot_confusion_matrix(y_test, predicted_y):

    '''y_test is our actual labels.

    predicted_y gives labels predicted by our model.

    In matrix each column heading is actual label . Each row is predicted label. '''

    

    '''Confusion Matrix'''

    C = confusion_matrix(y_test, predicted_y)

    print("Percentage of misclassified points by model :" , ((len(y_test) - np.trace(C))/(len(y_test)))*100 )

    #C will be a 9*9 matrix whoce each cell (i,j) will represent number of observations known to be in group i but predicted 

    #to be in group j. (This notation is opposite of wikipedia entry, or what we have learnned.)

    print(C)

    print("\n")

    labels = [1,2,3,4,5,6,7,8,9]

    cmap = sns.light_palette("green")

    #Representing Confusion matrix in heatmap format.

    print("-"*50, "confusion matrix", "-"*50)

    plt.figure(figsize=(10,5))

    sns.heatmap(C, annot=True, cmap=cmap, fmt=".3f", xticklabels=labels, yticklabels=labels)

    plt.xlabel('Predicted Class')

    plt.ylabel('Original Class')

    plt.show()

    

    

    '''Precision Matrix

    TP/(TP+FP) How precise we are in our result.

    Out of all the points which were predicted to be of class 1(TP+FP), how many were actually of class 1(TP). 

    Hence divide each column element from the sum of their respective column.

    '''

    A = (C/C.sum(axis=0))

    print("-"*50, "precision matrix", "-"*50)

    plt.figure(figsize=(10,5))

    sns.heatmap(A, annot=True, cmap=cmap, fmt=".3f", xticklabels=labels, yticklabels=labels)

    plt.xlabel('Predicted Class')

    plt.ylabel('Original Class')

    plt.show()

    print("Sum of columns in precision matrix",A.sum(axis=0))

    

    '''Recall Matrix

    TP/(FN+TP) How much were we able to remember from original dataframe.

    Out of all the points which were actually of class 1(TP+FN), how many are detected correctly from our model(TP)

    Divide each row element from the sum of their respeective rows.

    By default numpy divide column-wise.'''

    B = ((C.T/ C.sum(axis=1)).T)

    print("-"*50, "Recall matrix"    , "-"*50)

    plt.figure(figsize=(10,5))

    sns.heatmap(B, annot=True, cmap=cmap, fmt=".3f", xticklabels=labels, yticklabels=labels)

    plt.xlabel('Predicted Class')

    plt.ylabel('Original Class')

    plt.show()

    print("Sum of columns in precision matrix",B.sum(axis=1))



    

def perform_hyperparam_tuning(list_of_hyperparam, model_name,  x_train, y_train, x_cv, y_cv):

    cv_log_error_array = []

    for i in tqdm(list_of_hyperparam):

        if (model_name == "knn"):

            model =  KNeighborsClassifier(n_neighbors = i)

            #model.fit(x_train, y_train)

        elif(model_name == "lr"):

            model = LogisticRegression(penalty='l2',C=i,class_weight='balanced')

            #model.fit(x_train, y_train)

        elif(model_name == "rf"):

            model = RandomForestClassifier(n_estimators=i,random_state=42,n_jobs=-1, class_weight='balanced')

            #model.fit(x_train, y_train)

        elif(model_name == "xgbc"):

            #weights = []

            #a = y_train.value_counts().sort_index()

            #sum_a = a.sum()

            #for i in a:

            #    weights.append(sum_a/i)

            model = XGBClassifier(n_estimators=i,nthread=-1)

            #model.fit(x_train, y_train, sample_weight = weights)

        model.fit(x_train, y_train)

        caliberated_model = CalibratedClassifierCV(model, method = "sigmoid")

        caliberated_model.fit(x_train, y_train)

        predict_y = caliberated_model.predict_proba(x_cv)

        cv_log_error_array.append(log_loss(y_cv, predict_y))

    for i in range(len(cv_log_error_array)):

        print ('log_loss for hyper_parameter = ',list_of_hyperparam[i],'is',cv_log_error_array[i])

    return cv_log_error_array

       

def get_best_hyperparam(list_of_hyperparam, cv_log_error_array):

    index = np.argmin(cv_log_error_array)

    best_hyperparameter = list_of_hyperparam[index]

    return best_hyperparameter





def perform_on_best_hyperparam(model_name, best_hyperparameter, cv_log_error_array,x_train,y_train,x_cv,y_cv,x_test,y_test):

    

    if (model_name == "knn"):

            model =  KNeighborsClassifier(n_neighbors = best_hyperparameter)

    elif(model_name == "lr"):

            model = LogisticRegression(penalty = 'l2',C = best_hyperparameter,class_weight = 'balanced')

    elif(model_name == "rf"):

            model = RandomForestClassifier(n_estimators = best_hyperparameter,random_state = 42,n_jobs = -1,  class_weight='balanced')

    elif(model_name == "xgbc"):

            model = XGBClassifier(n_estimators = best_hyperparameter,nthread=-1)

            

    model.fit(x_train, y_train)

    

    caliberated_model = CalibratedClassifierCV(model, method = "sigmoid")

    caliberated_model.fit(x_train, y_train)



    predicted_y = caliberated_model.predict_proba(x_train)

    print("The training log-loss for best hyperparameter is", log_loss(y_train, predicted_y))

    predicted_y = caliberated_model.predict_proba(x_cv)

    print("The cv log-loss for best hyperparameter is", log_loss(y_cv, predicted_y))

    predicted_y = caliberated_model.predict_proba(x_test)

    print("The test log-loss for best hyperparameter is", log_loss(y_test, predicted_y))



    predicted_y = caliberated_model.predict(x_test)

    plot_confusion_matrix(y_test, predicted_y)

    



def plot_cv_error(list_of_hyperparam, cv_log_error_array):

    fig, ax = plt.subplots()

    ax.plot(list_of_hyperparam, cv_log_error_array,c='g')

    for i, txt in enumerate(np.round(cv_log_error_array,3)):

        ax.annotate((list_of_hyperparam[i],np.round(txt,3)), (list_of_hyperparam[i],cv_log_error_array[i]))

    plt.grid()

    plt.title("Cross Validation Error for each hyperparameter")

    plt.xlabel("Hyperparameter")

    plt.ylabel("Error measure")

    plt.show()

#Key idea here is we will generate random values for output.

#One way to generate random value is np.random.rand(1,9) .

#np.random.rand(1,9) -> array([[0.37220974, 0.22175184, 0.87718086, 0.85841599, 0.4761965 ,\

#                              0.65296651, 0.14017462, 0.04881395, 0.04505459]])

#sum(np.random.rand(1,9)) -> array([0.37220974, 0.22175184, 0.87718086, 0.85841599, 0.4761965 ,\

#                              0.65296651, 0.14017462, 0.04881395, 0.04505459]) Performs colummn wise sum.

#sum(sum(np.random.rand(1,9))) -> 3.6927646 finally a single integer.



#Hence key idea is that as output we will simply generate random values for every class.

cv_predicted_y = np.zeros((x_cv.shape[0],9))#For each data point in x_cv we will save the probability of each class label.

test_predicted_y = np.zeros((x_test.shape[0],9))#Similarly for each point in x_test.
#We need to generate 9 numbers and the sum of numbers should be 1.

#One solution is to genarate 9 numbers and divide each of the numbers by their sum.

for i in range(x_cv.shape[0]):

    random_probs = np.random.rand(1,9) #Explained above.

    cv_predicted_y[i] = (random_probs/sum(sum(random_probs)))[0] #random_probs/sum(sum(random_probs)) will return 2D array.

print("Log loss on Cross Validation data is ", log_loss(y_cv, cv_predicted_y))



for i in range(x_cv.shape[0]):

    random_probs = np.random.rand(1,9) #Explained above.

    test_predicted_y[i] = (random_probs/sum(sum(random_probs)))[0] #random_probs/sum(sum(random_probs)) will return 2D array.

print("Log loss on Cross Validation data is ", log_loss(y_test, test_predicted_y))



#Plot confusion matrix.

predicted_y = np.argmax(test_predicted_y, axis=1)

#It returns an array with indices of maximum value along axis. Here row-wise.

plot_confusion_matrix(y_test, predicted_y+1)
list_of_hyperparam = [x for x in range(1,15,2)]

model_name = "knn"

cv_log_error_array = perform_hyperparam_tuning(list_of_hyperparam, model_name,  x_train, y_train, x_cv, y_cv)
best_hyperparameter = get_best_hyperparam(list_of_hyperparam, cv_log_error_array)

perform_on_best_hyperparam(model_name, best_hyperparameter, cv_log_error_array,x_train,y_train,x_cv,y_cv,x_test,y_test)
plot_cv_error(list_of_hyperparam,cv_log_error_array)
list_of_hyperparam = [10 ** x for x in range(-5, 4)]

model_name = "lr"

cv_log_error_array = perform_hyperparam_tuning(list_of_hyperparam, model_name,  x_train, y_train, x_cv, y_cv)
best_hyperparameter = get_best_hyperparam(list_of_hyperparam, cv_log_error_array)

perform_on_best_hyperparam(model_name, best_hyperparameter, cv_log_error_array,x_train,y_train,x_cv,y_cv,x_test,y_test)
plot_cv_error(list_of_hyperparam,cv_log_error_array)
list_of_hyperparam = [10,50,100,500,1000,2000,3000]

model_name = "rf"

cv_log_error_array = perform_hyperparam_tuning(list_of_hyperparam, model_name,  x_train, y_train, x_cv, y_cv)
best_hyperparameter = get_best_hyperparam(list_of_hyperparam, cv_log_error_array)

perform_on_best_hyperparam(model_name, best_hyperparameter, cv_log_error_array,x_train,y_train,x_cv,y_cv,x_test,y_test)
plot_cv_error(list_of_hyperparam,cv_log_error_array)
list_of_hyperparam = [10,50,100,500,1000,2000]

model_name = "xgbc"

cv_log_error_array = perform_hyperparam_tuning(list_of_hyperparam, model_name,  x_train, y_train, x_cv, y_cv)
best_hyperparameter = get_best_hyperparam(list_of_hyperparam, cv_log_error_array)

perform_on_best_hyperparam(model_name, best_hyperparameter, cv_log_error_array,x_train,y_train,x_cv,y_cv,x_test,y_test)
plot_cv_error(list_of_hyperparam,cv_log_error_array)
#Let's load our final dataframe where sizes and features are merge.

asm_final_data = pd.read_csv("../input/asm_final_data.csv")

asm_final_data.head()
#Let's check columns which have absolutely no value.

sum_of_cols = asm_final_data.sum(axis = 0)

(sum_of_cols) 
# These columns -> .BSS, .CODE, rtn have absolutely no value drop them.

#Run it only once

asm_n = asm_final_data.drop(columns = ['.BSS:', '.CODE', 'rtn'], axis=1)
asm_n.shape
asm_result = normalize(asm_n)

asm_result.head()
asm_y = asm_result['Class']

asm_x = asm_result.drop(['Id','Class'], axis=1)
x_train_asm, x_test_asm, y_train_asm, y_test_asm = train_test_split(asm_x,asm_y ,stratify=asm_y,test_size=0.20)

x_train_asm, x_cv_asm, y_train_asm, y_cv_asm = train_test_split(x_train_asm, y_train_asm,stratify=y_train_asm,test_size=0.20)
list_of_hyperparam = [x for x in range(1,21,2)]

model_name = "knn"

cv_log_error_array = perform_hyperparam_tuning(list_of_hyperparam, model_name,  x_train_asm, y_train_asm, x_cv_asm, y_cv_asm)
best_hyperparameter = get_best_hyperparam(list_of_hyperparam, cv_log_error_array)

perform_on_best_hyperparam(model_name, best_hyperparameter, cv_log_error_array,x_train_asm,y_train_asm,x_cv_asm,y_cv_asm,x_test_asm,y_test_asm)
plot_cv_error(list_of_hyperparam,cv_log_error_array)
list_of_hyperparam = [10 ** x for x in range(-5, 4)]

model_name = "lr"

cv_log_error_array = perform_hyperparam_tuning(list_of_hyperparam, model_name,  x_train_asm, y_train_asm, x_cv_asm, y_cv_asm)
best_hyperparameter = get_best_hyperparam(list_of_hyperparam, cv_log_error_array)

perform_on_best_hyperparam(model_name, best_hyperparameter, cv_log_error_array,x_train_asm,y_train_asm,x_cv_asm,y_cv_asm,x_test_asm,y_test_asm)
plot_cv_error(list_of_hyperparam,cv_log_error_array)
list_of_hyperparam = [10,50,100,500,1000,2000,3000]

model_name = "rf"

cv_log_error_array = perform_hyperparam_tuning(list_of_hyperparam, model_name,  x_train_asm, y_train_asm, x_cv_asm, y_cv_asm)
best_hyperparameter = get_best_hyperparam(list_of_hyperparam, cv_log_error_array)

perform_on_best_hyperparam(model_name, best_hyperparameter, cv_log_error_array,x_train_asm,y_train_asm,x_cv_asm,y_cv_asm,x_test_asm,y_test_asm)
plot_cv_error(list_of_hyperparam,cv_log_error_array)
list_of_hyperparam = [10,50,100,500,1000,2000]

model_name = "xgbc"

cv_log_error_array = perform_hyperparam_tuning(list_of_hyperparam, model_name,  x_train_asm, y_train_asm, x_cv_asm, y_cv_asm)
best_hyperparameter = get_best_hyperparam(list_of_hyperparam, cv_log_error_array)

perform_on_best_hyperparam(model_name, best_hyperparameter, cv_log_error_array,x_train_asm,y_train_asm,x_cv_asm,y_cv_asm,x_test_asm,y_test_asm)
plot_cv_error(list_of_hyperparam,cv_log_error_array)
asm_result.head()
byte_result.head()
result_y = byte_result["Class"] #This will containg classes of all the data files.
final_byte_result = byte_result.drop(["Class"], axis = 1)
final_asm_result = asm_result.drop(["Class"], axis = 1)
result_x = pd.merge(final_byte_result, final_asm_result, on= "Id")

result_x.head()
result_x = result_x.drop(["Id"], axis=1)
#result_x and result_y will finally be used . They are already normalized.
x_train, x_test_merge, y_train, y_test_merge = train_test_split(result_x, result_y,stratify=result_y,test_size=0.20)

x_train_merge, x_cv_merge, y_train_merge, y_cv_merge = train_test_split(x_train, y_train,stratify=y_train,test_size=0.20)