from fastai import *

from fastai.text import *



import pandas as pd
bs = 32

path = Path('../input/innoplexusav/')
## Lets look at our data first

train = pd.read_csv(path/'train.csv'); train.head()
## Language model data

data_lm = TextLMDataBunch.from_csv(path, 'train.csv', text_cols='text')
## Language model Learner

learn_lm = language_model_learner(data_lm, AWD_LSTM, drop_mult=1.0, model_dir='/tmp/models')
## Look at some of the text generated by our language model



TEXT = "The color of the sky is"

N_WORDS = 40

N_SENTENCES = 2

print("\n".join(learn_lm.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))
learn_lm.lr_find()

learn_lm.recorder.plot()
lr = 1e-2/2

lr *= bs/48

learn_lm.to_fp16(); # converting the model to 1/2 precision. Helps the model to train faster
learn_lm.fit_one_cycle(1, lr*10, moms=(0.8,0.7)) # training only the head
learn_lm.unfreeze()

learn_lm.fit_one_cycle(10, lr, moms=(0.8,0.7)) # training the complete model
learn_lm.save('ft_lm') # saving the complete language model
learn_lm.save_encoder('ft_enc') # saving only the encoder part of the language model
# Classifier model data

data_clas = TextClasDataBunch.from_csv(path, 'train.csv',test='test.csv', text_cols='text', label_cols='sentiment', vocab=data_lm.vocab, bs=bs)
# learner for classification

learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5, model_dir='/tmp/models', metrics=[accuracy, FBeta(average='macro',beta=1)])

learn.load_encoder('ft_enc')
learn.lr_find()
learn.recorder.plot()
learn.fit_one_cycle(1, 2e-2, moms=(0.8,0.7))
learn.save('first')
## Gradually unfreezing 

learn.freeze_to(-2)

learn.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2), moms=(0.8,0.7))
learn.save('2nd')
# learn.load('2nd')
learn.freeze_to(-3)

learn.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))
learn.save('3rd')
## training the complete model

learn.unfreeze()

learn.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))
learn.save('clas')
test_df = pd.read_csv(path/'test.csv')

test_df.head()
test = TextList.from_csv(path, 'test.csv', cols='text')
learn.data.add_test(test) 
predictions, *_ = learn.get_preds(DatasetType.Test) # making predictions 

labels = np.argmax(predictions, 1)
labels
from sklearn.linear_model import LogisticRegression

from sklearn.model_selection import cross_val_score

from sklearn.feature_extraction.text import TfidfVectorizer

from sklearn.metrics import f1_score, fbeta_score
def score(y, y_pred):

    return fbeta_score(y, y_pred, beta=1, average='macro')



def evaluate_model(model, X, y):

    scores = cross_val_score(model, X, y, cv=3, n_jobs=-1)

    return scores.mean(), scores.std()
train = pd.read_csv(path/'train.csv')

train.head()
X = TfidfVectorizer(ngram_range=(1,3), stop_words='english', max_features=60000).fit_transform(train.text)

y = train.sentiment
model = LogisticRegression(class_weight='balanced')
evaluate_model(model, X,y)